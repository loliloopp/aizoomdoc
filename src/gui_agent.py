"""
–ê–¥–∞–ø—Ç–µ—Ä –∞–≥–µ–Ω—Ç–∞ –¥–ª—è —Ä–∞–±–æ—Ç—ã –≤ GUI (PyQt6).
–° –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –≤—ã–±–æ—Ä–∞ md —Ñ–∞–π–ª–æ–≤ –∏–∑ GUI.
"""

import logging
import json
import uuid
import asyncio
from pathlib import Path
from datetime import datetime
from typing import List
from PyQt6.QtCore import QThread, pyqtSignal

from .config import config
from .llm_client import LLMClient
from .image_processor import ImageProcessor
from .markdown_parser import MarkdownParser
from .supabase_client import supabase_client
from .s3_storage import s3_storage

logger = logging.getLogger(__name__)

class AgentWorker(QThread):
    sig_log = pyqtSignal(str)
    sig_message = pyqtSignal(str, str)
    sig_image = pyqtSignal(str, str)
    sig_finished = pyqtSignal()
    sig_error = pyqtSignal(str)
    sig_history_saved = pyqtSignal(str, str)
    sig_usage = pyqtSignal(int, int) # used, remaining
    
    def __init__(self, data_root: Path, query: str, model: str, md_files: List[str] = None, 
                 existing_chat_id: str = None, existing_db_chat_id: str = None, md_mode: str = "rag"):
        super().__init__()
        self.data_root = data_root
        self.query = query
        self.model = model
        self.md_files = md_files or []
        self.md_mode = md_mode
        self.is_running = True
        
        if existing_chat_id:
            self.chat_id = existing_chat_id
            self.is_new_chat = False
        else:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            self.chat_id = f"{timestamp}_{uuid.uuid4().hex[:6]}"
            self.is_new_chat = True
        
        self.chat_dir = data_root / "chats" / self.chat_id
        self.images_dir = self.chat_dir / "images"
        self.chat_dir.mkdir(parents=True, exist_ok=True)
        self.images_dir.mkdir(parents=True, exist_ok=True)
        
        self.db_chat_id = existing_db_chat_id
        
        if self.is_new_chat:
            self.chat_history_data = {
                "id": self.chat_id,
                "timestamp": datetime.now().strftime("%Y%m%d_%H%M%S"),
                "query": query,
                "model": model,
                "md_files": self.md_files,
                "messages": []
            }
        else:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –∏—Å—Ç–æ—Ä–∏—é
            history_path = self.chat_dir / "history.json"
            if history_path.exists():
                with open(history_path, "r", encoding="utf-8") as f:
                    self.chat_history_data = json.load(f)
                    # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤ –∏–∑ –∏—Å—Ç–æ—Ä–∏–∏, –µ—Å–ª–∏ –æ–Ω –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω —è–≤–Ω–æ
                    if not self.md_files and "md_files" in self.chat_history_data:
                        self.md_files = self.chat_history_data["md_files"]
            else:
                self.chat_history_data = {
                    "id": self.chat_id,
                    "timestamp": datetime.now().strftime("%Y%m%d_%H%M%S"),
                    "query": query,
                    "model": model,
                    "md_files": self.md_files,
                    "messages": []
                }

    def save_message(self, role: str, content: str, images: list = None):
        msg = {
            "role": role,
            "content": content,
            "timestamp": datetime.now().isoformat()
        }
        if images:
            msg["images"] = [img.image_path for img in images if img.image_path]
        
        self.chat_history_data["messages"].append(msg)
        self._save_to_disk()
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –ë–î –∏ S3
        if config.USE_DATABASE:
            try:
                asyncio.run(self._save_to_db(role, content, images))
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ –ë–î: {e}")

    async def _save_to_db(self, role: str, content: str, images: list = None):
        """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è –∏ –∫–∞—Ä—Ç–∏–Ω–æ–∫ –≤ Supabase –∏ S3."""
        try:
            if not self.db_chat_id:
                logger.warning("Supabase chat_id –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω, —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ")
                return

            # 1. –î–æ–±–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ
            msg_id = await supabase_client.add_message(
                chat_id=self.db_chat_id,
                role=role,
                content=content
            )
            
            if not msg_id:
                logger.warning("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ Supabase")
                return
            
            self._current_msg_id = msg_id # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–ª—è –ø—Ä–∏–≤—è–∑–∫–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞

            # 2. –ï—Å–ª–∏ –µ—Å—Ç—å –∫–∞—Ä—Ç–∏–Ω–∫–∏ - –∑–∞–≥—Ä—É–∂–∞–µ–º –≤ S3 –∏ —Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º
            if images:
                processed_paths = set()
                for img in images:
                    if not img.image_path or not Path(img.image_path).exists():
                        continue
                    
                    if img.image_path in processed_paths:
                        continue
                    processed_paths.add(img.image_path)
                        
                    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –ø—É—Ç—å –≤ S3
                    img_type = "zoom_crop" if img.is_zoom_request else "viewport"
                    filename = Path(img.image_path).name
                    s3_key = s3_storage.generate_s3_path(self.db_chat_id, img_type, filename)
                    
                    # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤ S3
                    try:
                        s3_url = await s3_storage.upload_file(img.image_path, s3_key)
                        
                        if s3_url:
                            # –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º –≤ –ë–î (—ç—Ç–æ —Ç–∞–∫–∂–µ —Å–æ–∑–¥–∞–µ—Ç –∑–∞–ø–∏—Å—å –≤ storage_files)
                            await supabase_client.add_image_to_message(
                                chat_id=self.db_chat_id,
                                message_id=msg_id,
                                image_name=filename,
                                s3_path=s3_key,
                                s3_url=s3_url,
                                image_type=img_type,
                                description=img.description
                            )
                            
                            # –ü–†–û–í–ï–†–ö–ê: –ï—Å–ª–∏ —ç—Ç–æ –ø—Ä–µ–≤—å—é, –∑–∞–≥—Ä—É–∂–∞–µ–º —Ç–∞–∫–∂–µ –∏ –æ—Ä–∏–≥–∏–Ω–∞–ª (full)
                            if "_preview.png" in img.image_path:
                                full_path = img.image_path.replace("_preview.png", "_full.png")
                                if Path(full_path).exists():
                                    s3_full_key = s3_key.replace("_preview.png", "_full.png")
                                    await s3_storage.upload_file(full_path, s3_full_key)
                                    # –ü—Ä–æ—Å—Ç–æ —Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º –≤ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ —Ñ–∞–π–ª–æ–≤
                                    await supabase_client.register_file(
                                        user_id="default_user",
                                        source_type="llm_generated",
                                        filename=Path(full_path).name,
                                        storage_path=s3_full_key
                                    )
                        else:
                            logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å {filename} –≤ S3 (s3_url is None)")
                    except Exception as upload_err:
                        logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏/—Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è {filename}: {upload_err}")
                        
        except Exception as e:
            logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ _save_to_db: {e}", exc_info=True)

    def _save_gui_search_log(self, query, text_snippets, doc_index):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –ª–æ–≥ –ø–æ–∏—Å–∫–∞ –¥–ª—è GUI-–≤–µ—Ä—Å–∏–∏."""
        import datetime
        from .doc_index import tokenize_query
        
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        log_path = self.data_root / f"search_log_gui_{timestamp}.md"
        
        try:
            tokens = tokenize_query(query)
            relevant_pages = sorted(list(set(
                entry.page for entry in doc_index.images.values() 
                if entry.page is not None and any(t in entry.searchable_text().lower() for t in tokens)
            )))

            with open(log_path, "w", encoding="utf-8") as f:
                f.write(f"# –õ–æ–≥ –ø–æ–∏—Å–∫–∞ (GUI): {query}\n\n")
                
                f.write("## 1. –ó–∞–ø—Ä–æ—Å\n")
                f.write(f"{query}\n\n")
                
                f.write("## 2. –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞-—Å–∏–Ω–æ–Ω–∏–º—ã (—Ç–æ–∫–µ–Ω—ã)\n")
                f.write(f"{', '.join(tokens)}\n\n")
                
                f.write("## 3. –°–ø–∏—Å–æ–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –±–ª–æ–∫–æ–≤\n")
                if text_snippets:
                    for i, (chunk_id, text) in enumerate(text_snippets, 1):
                        f.write(f"### –ë–ª–æ–∫ {i} (ID: {chunk_id})\n")
                        f.write(f"{text}\n\n")
                else:
                    f.write("–¢–µ–∫—Å—Ç–æ–≤—ã–µ –±–ª–æ–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã.\n\n")
                
                f.write("## 4. –†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–∑ –∫–∞—Ç–∞–ª–æ–≥–∞\n")
                # –ò—â–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –≤ –∫–æ—Ç–æ—Ä—ã—Ö –µ—Å—Ç—å —Ç–æ–∫–µ–Ω—ã –∑–∞–ø—Ä–æ—Å–∞
                found_images = False
                for entry in doc_index.images.values():
                    if any(t in entry.searchable_text().lower() for t in tokens):
                        f.write(f"- **{entry.image_id}** (—Å—Ç—Ä. {entry.page})\n")
                        f.write(f"  - –û–ø–∏—Å–∞–Ω–∏–µ: {entry.content_summary}\n")
                        f.write(f"  - –°—Å—ã–ª–∫–∞: {entry.uri}\n")
                        found_images = True
                if not found_images:
                    f.write("–†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ –∫–∞—Ç–∞–ª–æ–≥–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã.\n")
                
                f.write("\n## 5. –†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã (–Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–æ–∏—Å–∫–∞ –ø–æ –∫–∞—Ç–∞–ª–æ–≥—É)\n")
                if relevant_pages:
                    f.write(f"{', '.join(map(str, relevant_pages))}\n")
                else:
                    f.write("–†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω—ã.\n")
            
            logger.info(f"–õ–æ–≥ –ø–æ–∏—Å–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {log_path.absolute()}")
            print(f"--- SEARCH LOG SAVED: {log_path.absolute()} ---")
            self.sig_log.emit(f"–õ–æ–≥ –ø–æ–∏—Å–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {log_path.name}")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –ª–æ–≥–∞ –ø–æ–∏—Å–∫–∞ (GUI): {e}")

    def _save_to_disk(self):
        history_path = self.chat_dir / "history.json"
        with open(history_path, "w", encoding="utf-8") as f:
            json.dump(self.chat_history_data, f, indent=2, ensure_ascii=False)
        self.sig_history_saved.emit(self.chat_id, self.query)

    def run(self):
        try:
            self.sig_log.emit(f"–°—Ç–∞—Ä—Ç —á–∞—Ç–∞ {self.chat_id}...")
            self._current_msg_id = None # –î–ª—è –ø—Ä–∏–≤—è–∑–∫–∏ –±–ª–æ–∫–æ–≤ –∫ —Å–æ–æ–±—â–µ–Ω–∏—é
            
            # 0. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —á–∞—Ç–∞ –≤ Supabase (—Ç–æ–ª—å–∫–æ –¥–ª—è –Ω–æ–≤—ã—Ö —á–∞—Ç–æ–≤)
            if config.USE_DATABASE and not self.db_chat_id:
                try:
                    title = self.query[:100]
                    self.db_chat_id = asyncio.run(supabase_client.create_chat(
                        title=title,
                        user_id="default_user",
                        description=self.query,
                        metadata={
                            "local_chat_id": self.chat_id,
                            "model": self.model,
                            "md_files": self.md_files
                        }
                    ))
                    if self.db_chat_id:
                        self.sig_log.emit(f"–ß–∞—Ç –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω –≤ –æ–±–ª–∞–∫–µ: {self.db_chat_id}")
                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —á–∞—Ç–∞ –≤ Supabase: {e}")

            image_processor = ImageProcessor(self.data_root)
            image_processor.temp_dir = self.images_dir
            
            llm_client = LLMClient(model=self.model, data_root=self.data_root)
            
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –¥–∏–∞–ª–æ–≥ —Å –∏—Å—Ç–æ—Ä–∏–µ–π, –µ—Å–ª–∏ –æ–Ω–∞ –µ—Å—Ç—å
            from .llm_client import load_analysis_prompt
            analysis_prompt = load_analysis_prompt(self.data_root)
            llm_client.history = [{"role": "system", "content": analysis_prompt}]

            # –ö—Ä–∞—Ç–∫–∞—è –ø–∞–º—è—Ç—å –¥–∏–∞–ª–æ–≥–∞ (—É—Å—Ç–æ–π—á–∏–≤–æ –¥–ª—è –¥–ª–∏–Ω–Ω—ã—Ö —á–∞—Ç–æ–≤)
            memory_path = self.chat_dir / "memory.txt"
            if memory_path.exists():
                try:
                    memory_text = memory_path.read_text(encoding="utf-8").strip()
                    if memory_text:
                        llm_client.history.append(
                            {"role": "system", "content": f"–ö–†–ê–¢–ö–ê–Ø –ü–ê–ú–Ø–¢–¨ –î–ò–ê–õ–û–ì–ê (–æ–±–Ω–æ–≤–ª—è–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏):\n{memory_text}"}
                        )
                except Exception as e:
                    logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å memory.txt: {e}")

            # –î–ª—è –∏—Å—Ç–æ—Ä–∏–∏ –¥–æ–±–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è (–æ—Å—Ç–∞–ª—å–Ω–æ–µ —Å–∂–∏–º–∞–µ—Ç—Å—è –≤ memory.txt).
            # –≠—Ç–æ –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç —Ä–æ—Å—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –≤ –±–µ—Å–∫–æ–Ω–µ—á–Ω–æ–º –¥–∏–∞–ª–æ–≥–µ.
            history_messages = self.chat_history_data.get("messages", [])
            tail_n = 12
            for msg in history_messages[-tail_n:]:
                llm_client.history.append({"role": msg.get("role", "user"), "content": msg.get("content", "")})

            # –ï—Å–ª–∏ —É–∫–∞–∑–∞–Ω—ã –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ md —Ñ–∞–π–ª—ã —á–µ—Ä–µ–∑ GUI - –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏—Ö
            full_text = ""
            all_blocks = []
            
            # –í–ê–ñ–ù–û: –ï—Å–ª–∏ –º—ã –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º —á–∞—Ç, –Ω–∞–º –≤—Å–µ —Ä–∞–≤–Ω–æ –Ω—É–∂–µ–Ω —Ç–µ–∫—Å—Ç –¥–æ–∫—É–º–µ–Ω—Ç–∞ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ.
            # –î–ª—è –≤–∞—Ä–∏–∞–Ω—Ç–∞ A –º—ã –ø—Ä–æ—Å—Ç–æ –∑–∞–Ω–æ–≤–æ —á–∏—Ç–∞–µ–º —Ñ–∞–π–ª—ã.
            if self.md_files:
                self.sig_log.emit(f"–ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –≤—ã–±—Ä–∞–Ω–Ω—ã–µ MD —Ñ–∞–π–ª—ã: {len(self.md_files)}")
                for md_path_str in self.md_files:
                    try:
                        md_path = Path(md_path_str)
                        self.sig_log.emit(f"–ß–∏—Ç–∞—é: {md_path}")
                        
                        # –ó–∞–≥—Ä—É–∂–∞–µ–º MD –≤ S3 –∏ —Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º –≤ –ë–î
                        if self.db_chat_id:
                            try:
                                s3_doc_key = s3_storage.generate_s3_path(self.db_chat_id, "document", md_path.name)
                                s3_url = asyncio.run(s3_storage.upload_file(str(md_path), s3_doc_key))
                                
                                asyncio.run(supabase_client.register_file(
                                    user_id="default_user",
                                    source_type="user_upload",
                                    filename=md_path.name,
                                    storage_path=s3_doc_key,
                                    external_url=s3_url
                                ))
                            except Exception as e:
                                logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏/—Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏ MD: {e}")

                        parser = MarkdownParser(md_path)
                        blocks = parser.parse()
                        all_blocks.extend(blocks)
                        
                        self.sig_log.emit(f"–ü—Ä–æ—á–∏—Ç–∞–Ω–æ –±–ª–æ–∫–æ–≤: {len(blocks)}")
                        for block in blocks:
                            full_text += block.text + "\n\n"
                            
                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –±–ª–æ–∫–∏ –≤ search_results
                        if self.db_chat_id:
                            try:
                                # –î–ª—è –≤–∞—Ä–∏–∞–Ω—Ç–∞ A –ø—Ä–∏–≤—è–∑—ã–≤–∞–µ–º –±–ª–æ–∫–∏ –∫ —á–∞—Ç—É.
                                # –ï—Å–ª–∏ –≤ –ë–î message_id –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω, —Ç–æ –¥–ª—è –ø–µ—Ä–≤–∏—á–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞ 
                                # –º—ã –ø–æ–∫–∞ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –∏–ª–∏ –ø—Ä–∏–≤—è–∑—ã–≤–∞–µ–º –∫ –±—É–¥—É—â–µ–º—É —Å–æ–æ–±—â–µ–Ω–∏—é.
                                pass
                            except Exception as e:
                                logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –±–ª–æ–∫–∞: {e}")

                    except Exception as e:
                        self.sig_log.emit(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è {md_path_str}: {e}")
                        import traceback
                        self.sig_log.emit(traceback.format_exc())
            else:
                # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –±–µ—Ä–µ–º result.md
                self.sig_log.emit(f"–ò—â—É result.md –≤ {self.data_root}")
                markdown_path, _ = config.get_document_paths(self.data_root)
                if Path(markdown_path).exists():
                    parser = MarkdownParser(markdown_path)
                    blocks = parser.parse()
                    all_blocks = blocks
                    
                    # –ó–∞–≥—Ä—É–∂–∞–µ–º MD –≤ S3
                    if self.db_chat_id:
                        try:
                            s3_doc_key = s3_storage.generate_s3_path(self.db_chat_id, "document", Path(markdown_path).name)
                            s3_url = asyncio.run(s3_storage.upload_file(str(markdown_path), s3_doc_key))
                            asyncio.run(supabase_client.register_file(
                                user_id="default_user",
                                source_type="user_upload",
                                filename=Path(markdown_path).name,
                                storage_path=s3_doc_key,
                                external_url=s3_url
                            ))
                        except: pass

                    for block in blocks:
                        full_text += block.text + "\n\n"
                        
                        if self.db_chat_id:
                            try:
                                asyncio.run(supabase_client.add_search_result(
                                    chat_id=self.db_chat_id,
                                    message_id=None,
                                    block_id=block.block_id,
                                    block_text=block.text[:1000]
                                ))
                            except: pass
            
            if not full_text.strip():
                raise ValueError("–í —á–∞—Ç–µ –Ω–µ—Ç –ø—Ä–∏–∫—Ä–µ–ø–ª–µ–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞. –ü—Ä–∏–∫—Ä–µ–ø–∏—Ç–µ .md —Ñ–∞–π–ª—ã.")

            # 1. –ß–∏—Ç–∞–µ–º –∏ —Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º MD —Ñ–∞–π–ª—ã
            full_md_text = ""
            all_blocks = []
            
            # –°–æ–±–∏—Ä–∞–µ–º —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
            files_to_process = []
            if self.md_files:
                files_to_process = self.md_files
            else:
                markdown_path, _ = config.get_document_paths(self.data_root)
                if Path(markdown_path).exists():
                    files_to_process = [str(markdown_path)]

            for md_path_str in files_to_process:
                try:
                    md_path = Path(md_path_str)
                    self.sig_log.emit(f"–û–±—Ä–∞–±–æ—Ç–∫–∞: {md_path.name}")
                    
                    # –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –≤ S3/DB
                    if self.db_chat_id:
                        try:
                            s3_doc_key = s3_storage.generate_s3_path(self.db_chat_id, "document", md_path.name)
                            s3_url = asyncio.run(s3_storage.upload_file(str(md_path), s3_doc_key))
                            asyncio.run(supabase_client.register_file(
                                user_id="default_user",
                                source_type="user_upload",
                                filename=md_path.name,
                                storage_path=s3_doc_key,
                                external_url=s3_url
                            ))
                        except: pass

                    # –ß—Ç–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞
                    text = md_path.read_text(encoding="utf-8")
                    full_md_text += text + "\n\n"
                    
                    # –ü–∞—Ä—Å–∏–Ω–≥ –±–ª–æ–∫–æ–≤ –¥–ª—è RAG –∏ –ø–æ–∏—Å–∫–∞
                    parser = MarkdownParser(md_path)
                    all_blocks.extend(parser.parse())
                except Exception as e:
                    self.sig_log.emit(f"–û—à–∏–±–∫–∞ —Ñ–∞–π–ª–∞ {md_path_str}: {e}")

            if not full_md_text.strip():
                raise ValueError("–ù–µ—Ç —Ç–µ–∫—Å—Ç–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞.")

            # ===== –ü–û–î–ì–û–¢–û–í–ö–ê –ö–û–ù–¢–ï–ö–°–¢–ê =====
            
            from .doc_index import build_index, retrieve_text_chunks, strip_json_blocks
            doc_index = build_index(full_md_text)
            
            tail_n = 12 # –ù–∞—á–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –∏—Å—Ç–æ—Ä–∏–∏
            context = ""
            
            # –¶–∏–∫–ª —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ —Å –ø–æ–ø—ã—Ç–∫–æ–π –≤–ø–∏—Ö–Ω—É—Ç—å –º–∞–∫—Å–∏–º—É–º
            while tail_n >= 0:
                # –û—á–∏—â–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é –¥–ª—è –Ω–æ–≤–æ–π –ø–æ–ø—ã—Ç–∫–∏
                llm_client.history = [{"role": "system", "content": analysis_prompt}]
                if memory_path.exists():
                    try:
                        mem = memory_path.read_text(encoding="utf-8").strip()
                        if mem: llm_client.history.append({"role": "system", "content": f"–ö–†–ê–¢–ö–ê–Ø –ü–ê–ú–Ø–¢–¨: {mem}"})
                    except: pass
                
                # –î–æ–±–∞–≤–ª—è–µ–º —Ö–≤–æ—Å—Ç –∏—Å—Ç–æ—Ä–∏–∏
                history_messages = self.chat_history_data.get("messages", [])
                for msg in history_messages[-(tail_n if tail_n > 0 else 0):] if tail_n > 0 else []:
                    llm_client.history.append({"role": msg.get("role", "user"), "content": msg.get("content", "")})

                if self.md_mode == "full_md":
                    self.sig_log.emit(f"–†–µ–∂–∏–º: –ü–æ–ª–Ω—ã–π MD (history_n={tail_n})...")
                    img_entries = sorted(doc_index.images.values(), key=lambda e: ((e.page or 0), e.image_id))
                    catalog_text = "\n".join([f"- {e.image_id} (—Å—Ç—Ä. {e.page}): {e.content_summary[:150]}" for e in img_entries])
                    
                    context = (
                        f"–ó–ê–ü–†–û–° –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø:\n{self.query}\n\n"
                        f"–ü–û–õ–ù–´–ô –¢–ï–ö–°–¢ –î–û–ö–£–ú–ï–ù–¢–ê:\n{strip_json_blocks(full_md_text)}\n\n"
                        f"–ö–ê–¢–ê–õ–û–ì –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–ô:\n{catalog_text}\n\n"
                        f"–ò—Å–ø–æ–ª—å–∑—É–π tool=request_images –∏ tool=zoom –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –≥—Ä–∞—Ñ–∏–∫–æ–π."
                    )
                else:
                    self.sig_log.emit(f"–†–µ–∂–∏–º: RAG (history_n={tail_n})...")
                    text_snippets = retrieve_text_chunks(doc_index, self.query, top_k=10)
                    self._save_gui_search_log(self.query, text_snippets, doc_index)
                    
                    img_entries = sorted(doc_index.images.values(), key=lambda e: ((e.page or 0), e.image_id))
                    catalog_text = "\n".join([f"- {e.image_id} (—Å—Ç—Ä. {e.page}): {e.content_summary[:180]}" for e in img_entries])
                    snippets_text = "\n\n".join([f"[{cid}]\n{txt}" for cid, txt in text_snippets])
                    
                    context = (
                        f"–ó–ê–ü–†–û–° –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø:\n{self.query}\n\n"
                        f"–†–ï–õ–ï–í–ê–ù–¢–ù–´–ï –§–†–ê–ì–ú–ï–ù–¢–´:\n{snippets_text}\n\n"
                        f"–ö–ê–¢–ê–õ–û–ì –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–ô:\n{catalog_text}\n\n"
                        f"–ò—Å–ø–æ–ª—å–∑—É–π tool=request_images –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ —á–µ—Ä—Ç–µ–∂–µ–π."
                    )

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –≤–ª–µ–∑–∞–µ—Ç –ª–∏
                temp_history = llm_client.history + [{"role": "user", "content": context}]
                est = llm_client.build_context_report(temp_history, max_tokens=4000)
                
                if not est.get("will_overflow"):
                    self.sig_log.emit(f"OK: –ü—Ä–æ–º–ø—Ç ~{est.get('prompt_tokens_est')} —Ç–æ–∫–µ–Ω–æ–≤.")
                    break
                
                if self.md_mode == "full_md" and tail_n == 0:
                    self.sig_log.emit("‚ö†Ô∏è –î–∞–∂–µ –±–µ–∑ –∏—Å—Ç–æ—Ä–∏–∏ –Ω–µ –≤–ª–µ–∑–∞–µ—Ç. Fallback –≤ RAG...")
                    self.md_mode = "rag"
                    tail_n = 12 # –°–±—Ä–∞—Å—ã–≤–∞–µ–º tail_n –¥–ª—è RAG
                    continue
                
                tail_n -= 3 # –£–º–µ–Ω—å—à–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é –∏ –ø—Ä–æ–±—É–µ–º —Å–Ω–æ–≤–∞
                self.sig_log.emit(f"‚ö†Ô∏è –ü–µ—Ä–µ–ø–æ–ª–Ω–µ–Ω–∏–µ. –°–æ–∫—Ä–∞—â–∞—é –∏—Å—Ç–æ—Ä–∏—é –¥–æ {tail_n}...")

            self.save_message("user", self.query, images=None)
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞ –≤ –ë–î (–ø–∞–∫–µ—Ç–Ω–æ)
            if self.db_chat_id and hasattr(self, '_current_msg_id') and self._current_msg_id:
                bulk_data = [{"chat_id": self.db_chat_id, "message_id": self._current_msg_id, "block_id": b.block_id, "block_text": b.text[:1000]} for b in all_blocks]
                if bulk_data:
                    try: asyncio.run(supabase_client.add_search_results_bulk(bulk_data))
                    except: pass

            llm_client.add_user_message(context, images=None)
            
            step = 0
            max_steps = 5
            
            while step < max_steps and self.is_running:
                step += 1
                self.sig_log.emit(f"–®–∞–≥ {step}...")

                # –ü—Ä–æ–≥–Ω–æ–∑ –ø–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É
                try:
                    est = llm_client.last_prompt_estimate or llm_client.build_context_report(llm_client.history, max_tokens=4000)
                    if est and est.get("will_overflow"):
                        self.sig_log.emit("‚ö†Ô∏è –†–∏—Å–∫ –ø–µ—Ä–µ–ø–æ–ª–Ω–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –Ω–∞ —Ç–µ–∫—É—â–µ–º —à–∞–≥–µ!")
                except: pass
                
                try:
                    response = llm_client.get_response()
                except Exception as e:
                    if "context_length" in str(e).lower():
                        err = "–ö—Ä–∏—Ç–∏—á–µ—Å–∫–æ–µ –ø–µ—Ä–µ–ø–æ–ª–Ω–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Ä–µ–∂–∏–º RAG –∏–ª–∏ –¥—Ä—É–≥—É—é –º–æ–¥–µ–ª—å."
                        self.sig_log.emit(f"‚ùå {err}")
                        self.save_message("system", err)
                        raise ValueError(err)
                    raise e
                
                # –î–∞–ª—å—à–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ response (request_images, zoom, –∏ —Ç.–¥.)
                # ... (—Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∫–æ–¥ –Ω–∏–∂–µ) ...
                print(f"[GUI_AGENT] –ü–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç –¥–ª–∏–Ω–æ–π {len(response)} —Å–∏–º–≤–æ–ª–æ–≤")
                print(f"[GUI_AGENT] –ü–µ—Ä–≤—ã–µ 300 —Å–∏–º–≤–æ–ª–æ–≤ –æ—Ç–≤–µ—Ç–∞: {response[:300]}")

                # –§–∞–∫—Ç –ø–æ usage (–∞–Ω–∞–ª–∏–∑)
                try:
                    usage = llm_client.last_usage
                    if isinstance(usage, dict) and usage.get("prompt_tokens") is not None:
                        pt = usage.get("prompt_tokens")
                        ct = usage.get("completion_tokens")
                        tt = usage.get("total_tokens")
                        ctx = llm_client.get_model_context_length()
                        rem = (ctx - pt) if (isinstance(ctx, int) and isinstance(pt, int)) else None
                        self.sig_log.emit(
                            f"[–ö–æ–Ω—Ç–µ–∫—Å—Ç/—Ñ–∞–∫—Ç][–∞–Ω–∞–ª–∏–∑] prompt={pt}, completion={ct}, total={tt}, "
                            f"–ª–∏–º–∏—Ç={ctx if ctx is not None else '–Ω–µ–∏–∑–≤.'}, –æ—Å—Ç–∞—Ç–æ–∫={rem if rem is not None else '–Ω–µ–∏–∑–≤.'}"
                        )
                        if isinstance(pt, int) and isinstance(rem, int):
                            self.sig_usage.emit(pt, rem)
                except Exception:
                    pass
                
                # 1) –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∑–∞–ø—Ä–æ—Å—ã –Ω–∞ –ø–æ–¥–≥—Ä—É–∑–∫—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
                img_reqs = llm_client.parse_image_requests(response)
                if img_reqs:
                    # –°–æ–±–∏—Ä–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ id
                    req_ids = []
                    for r in img_reqs:
                        for rid in r.image_ids:
                            rid = str(rid).strip()
                            if rid.endswith(".pdf"):
                                rid = rid[:-4]
                            if rid and rid not in req_ids:
                                req_ids.append(rid)

                    info_msg = f"üñºÔ∏è –ó–∞–ø—Ä–æ—à–µ–Ω—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {', '.join(req_ids[:15])}{' ...' if len(req_ids) > 15 else ''}"
                    self.sig_message.emit("assistant", info_msg)
                    self.save_message("assistant", info_msg)

                    downloaded_imgs = []
                    missing_ids = []
                    for rid in req_ids:
                        if not self.is_running:
                            return
                        entry = doc_index.images.get(rid)
                        if not entry:
                            missing_ids.append(rid)
                            continue
                        self.sig_log.emit(f"–°–∫–∞—á–∏–≤–∞–Ω–∏–µ (–ø–æ id): {rid}")
                        crop_info = image_processor.download_and_process_pdf(entry.uri, image_id=rid)
                        if crop_info:
                            downloaded_imgs.append(crop_info)
                            if crop_info.image_path:
                                self.sig_image.emit(crop_info.image_path, f"Image ID: {rid}")

                    if missing_ids:
                        warn = f"‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω–æ –≤ –∫–∞—Ç–∞–ª–æ–≥–µ: {', '.join(missing_ids[:10])}{' ...' if len(missing_ids) > 10 else ''}"
                        self.sig_log.emit(warn)
                        self.save_message("assistant", warn)

                    if downloaded_imgs:
                        self.save_message("assistant", "üñºÔ∏è –ó–∞–≥—Ä—É–∂–µ–Ω—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø–æ –∑–∞–ø—Ä–æ—Å—É –º–æ–¥–µ–ª–∏.", images=downloaded_imgs)
                        llm_client.add_user_message("–ó–∞–ø—Ä–æ—à–µ–Ω–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:", images=downloaded_imgs)
                        # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Ü–∏–∫–ª ‚Äî –º–æ–¥–µ–ª—å —É–≤–∏–¥–∏—Ç –∫–∞—Ä—Ç–∏–Ω–∫–∏ –∏ —Å–º–æ–∂–µ—Ç –∑–∞–ø—Ä–æ—Å–∏—Ç—å zoom/—Å–¥–µ–ª–∞—Ç—å –≤—ã–≤–æ–¥—ã
                        continue
                    else:
                        # –ù–µ—á–µ–≥–æ –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å –º–æ–¥–µ–ª–∏ ‚Äî –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º, —á—Ç–æ–±—ã –æ–Ω–∞ –º–æ–≥–ª–∞ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –∑–∞–ø—Ä–æ—Å
                        llm_client.add_user_message("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∑–∞–ø—Ä–æ—à–µ–Ω–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è. –ü–æ–ø—Ä–æ–±—É–π —É–∫–∞–∑–∞—Ç—å –¥—Ä—É–≥–∏–µ image_ids –∏–∑ –∫–∞—Ç–∞–ª–æ–≥–∞.")
                        continue

                zoom_reqs = llm_client.parse_zoom_request(response)
                print(f"[GUI_AGENT] Zoom –∑–∞–ø—Ä–æ—Å–æ–≤: {len(zoom_reqs)}")
                
                if zoom_reqs:
                    zoom_crops = []
                    for i, zr in enumerate(zoom_reqs):
                        zoom_msg = f"üîÑ *Zoom [{i+1}/{len(zoom_reqs)}]:* {zr.reason}"
                        self.sig_log.emit(zoom_msg)
                        self.sig_message.emit("assistant", zoom_msg)

                        # –ï—Å–ª–∏ –º–æ–¥–µ–ª—å –ø—Ä–æ—Å–∏—Ç zoom –ø–æ image_id, –Ω–æ –±–∞–∑–æ–≤–∞—è –∫–∞—Ä—Ç–∏–Ω–∫–∞ –µ—â—ë –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞ ‚Äî
                        # –ø–æ–¥–≥—Ä—É–∂–∞–µ–º –µ—ë –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–æ –∫–∞—Ç–∞–ª–æ–≥—É (—É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å).
                        try:
                            img_id = getattr(zr, "image_id", None)
                            if isinstance(img_id, str) and img_id:
                                # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è: –∏–Ω–æ–≥–¥–∞ –º–æ–¥–µ–ª—å –ø—Ä–∏—Å—ã–ª–∞–µ—Ç id —Å .pdf
                                if img_id.endswith(".pdf"):
                                    img_id = img_id[:-4]
                                    zr.image_id = img_id
                                if img_id not in getattr(image_processor, "_image_cache", {}):
                                    entry = doc_index.images.get(img_id)
                                    if entry:
                                        self.sig_log.emit(f"–ü–æ–¥–≥—Ä—É–∂–∞—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è zoom: {img_id}")
                                        image_processor.download_and_process_pdf(entry.uri, image_id=img_id)
                        except Exception as e:
                            self.sig_log.emit(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è zoom: {e}")
                        
                        zoom_crop = image_processor.process_zoom_request(
                            zr,
                            output_path=self.images_dir / f"zoom_step_{step}_{i}.png"
                        )
                        
                        if zoom_crop:
                            zoom_crops.append(zoom_crop)
                            if zoom_crop.image_path:
                                self.sig_image.emit(zoom_crop.image_path, f"Zoom {i+1}")
                        else:
                            self.sig_log.emit(f"–û—à–∏–±–∫–∞ Zoom {i+1}")

                    if zoom_crops:
                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é –∏ –ë–î –û–î–ù–ò–ú —Å–æ–æ–±—â–µ–Ω–∏–µ–º —Å–æ –≤—Å–µ–º–∏ –∫–∞—Ä—Ç–∏–Ω–∫–∞–º–∏
                        reasons = " | ".join([zr.reason for zr in zoom_reqs])
                        self.save_message("assistant", f"üîé –í—ã–ø–æ–ª–Ω–µ–Ω Zoom:\n{reasons}", images=zoom_crops)
                        llm_client.add_user_message("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã Zoom:", images=zoom_crops)
                    else:
                        self.sig_log.emit("–û—à–∏–±–∫–∞ Zoom: –Ω–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã.")
                        self.save_message("assistant", "‚ö†Ô∏è –û—à–∏–±–∫–∞ Zoom: –Ω–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã.")
                else:
                    self.sig_message.emit("assistant", response)
                    self.save_message("assistant", response)

                    # –û–±–Ω–æ–≤–ª—è–µ–º –∫—Ä–∞—Ç–∫—É—é –ø–∞–º—è—Ç—å –¥–∏–∞–ª–æ–≥–∞ (–¥–ª—è —É—Å—Ç–æ–π—á–∏–≤—ã—Ö –¥–ª–∏–Ω–Ω—ã—Ö —á–∞—Ç–æ–≤)
                    try:
                        prev_mem = ""
                        if memory_path.exists():
                            prev_mem = memory_path.read_text(encoding="utf-8").strip()
                        new_mem = llm_client.update_memory_summary(prev_mem, self.query, response)
                        if new_mem:
                            memory_path.write_text(new_mem.strip(), encoding="utf-8")
                    except Exception as e:
                        logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±–Ω–æ–≤–∏—Ç—å –ø–∞–º—è—Ç—å –¥–∏–∞–ª–æ–≥–∞: {e}")

                    self.sig_finished.emit()
                    return

            if self.is_running:
                err = "–õ–∏–º–∏—Ç —à–∞–≥–æ–≤."
                self.sig_error.emit(err)
                self.save_message("system", err)
                
        except Exception as e:
            logger.error(f"Error: {e}", exc_info=True)
            self.sig_error.emit(str(e))
            self.sig_finished.emit()

    def stop(self):
        self.is_running = False
