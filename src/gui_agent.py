"""
–ê–¥–∞–ø—Ç–µ—Ä –∞–≥–µ–Ω—Ç–∞ –¥–ª—è —Ä–∞–±–æ—Ç—ã –≤ GUI (PyQt6).
–° –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –≤—ã–±–æ—Ä–∞ md —Ñ–∞–π–ª–æ–≤ –∏–∑ GUI.
"""

import logging
import json
import uuid
import asyncio
import copy
from pathlib import Path
from datetime import datetime
from typing import List
from PyQt6.QtCore import QThread, pyqtSignal

from .config import config
from .llm_client import LLMClient
from .image_processor import ImageProcessor
from .markdown_parser import MarkdownParser
from .file_processor import FileProcessor
from .html_ocr_processor import HtmlOcrProcessor
from .supabase_client import supabase_client
from .s3_storage import s3_storage
from .schemas import PRO_ANSWER_SCHEMA, FLASH_EXTRACTOR_SCHEMA

logger = logging.getLogger(__name__)

class AgentWorker(QThread):
    sig_log = pyqtSignal(str)
    sig_message = pyqtSignal(str, str, str)  # role, content, model
    sig_image = pyqtSignal(str, str)
    sig_finished = pyqtSignal()
    sig_error = pyqtSignal(str)
    sig_history_saved = pyqtSignal(str, str)
    sig_usage = pyqtSignal(int, int) # used, remaining
    
    def __init__(self, data_root: Path, query: str, model: str, md_files: List[str] = None, 
                 existing_chat_id: str = None, existing_db_chat_id: str = None, md_mode: str = "full_md",
                 user_prompt: str = None):
        super().__init__()
        self.data_root = data_root
        self.query = query
        self.model = model
        self.md_files = md_files or []
        # –†–µ–∂–∏–º RAG —É–±—Ä–∞–Ω ‚Äî –≤—Å–µ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º full_md
        self.md_mode = "full_md"
        self.user_prompt = user_prompt
        self.is_running = True
        
        # –°—á–µ—Ç—á–∏–∫ —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ —á–∞—Ç–∞
        self.total_tokens_used = 0
        
        if existing_chat_id:
            self.chat_id = existing_chat_id
            self.is_new_chat = False
        else:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            self.chat_id = f"{timestamp}_{uuid.uuid4().hex[:6]}"
            self.is_new_chat = True
        
        self.chat_dir = data_root / "chats" / self.chat_id
        self.images_dir = self.chat_dir / "images"
        self.chat_dir.mkdir(parents=True, exist_ok=True)
        self.images_dir.mkdir(parents=True, exist_ok=True)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∏–º—è —Ñ–∞–π–ª–∞ –ª–æ–≥–∞ —Å –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω—ã–º –∏–Ω–¥–µ–∫—Å–æ–º –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
        log_idx = 1
        while (self.chat_dir / f"full_log_{log_idx}.txt").exists():
            log_idx += 1
        self.full_log_path = self.chat_dir / f"full_log_{log_idx}.txt"
        
        self.db_chat_id = existing_db_chat_id
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–æ–∫–µ–Ω—ã –∏–∑ –ë–î –¥–ª—è —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ —á–∞—Ç–∞
        if not self.is_new_chat and self.db_chat_id and supabase_client.is_connected():
            try:
                chat_data = asyncio.run(supabase_client.get_chat(self.db_chat_id))
                if chat_data and chat_data.get("metadata"):
                    metadata = chat_data["metadata"]
                    self.total_tokens_used = metadata.get("total_tokens", 0)
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ç–æ–∫–µ–Ω–æ–≤ –∏–∑ –ë–î: {e}")
        
        if self.is_new_chat:
            self.chat_history_data = {
                "id": self.chat_id,
                "timestamp": datetime.now().strftime("%Y%m%d_%H%M%S"),
                "query": query,
                "model": model,
                "md_files": self.md_files,
                "messages": []
            }
        else:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –∏—Å—Ç–æ—Ä–∏—é
            history_path = self.chat_dir / "history.json"
            if history_path.exists():
                with open(history_path, "r", encoding="utf-8") as f:
                    self.chat_history_data = json.load(f)
                    # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤ –∏–∑ –∏—Å—Ç–æ—Ä–∏–∏, –µ—Å–ª–∏ –æ–Ω –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω —è–≤–Ω–æ
                    if not self.md_files and "md_files" in self.chat_history_data:
                        self.md_files = self.chat_history_data["md_files"]
            else:
                self.chat_history_data = {
                    "id": self.chat_id,
                    "timestamp": datetime.now().strftime("%Y%m%d_%H%M%S"),
                    "query": query,
                    "model": model,
                    "md_files": self.md_files,
                    "messages": []
                }

    def save_message(self, role: str, content: str, images: list = None):
        msg = {
            "role": role,
            "content": content,
            "timestamp": datetime.now().isoformat()
        }
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å –¥–ª—è —Å–æ–æ–±—â–µ–Ω–∏–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞
        if role == "assistant":
            msg["model"] = self.model
            
        if images:
            msg["images"] = [img.image_path for img in images if img.image_path]
        
        self.chat_history_data["messages"].append(msg)
        self._save_to_disk()
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –ë–î –∏ S3
        # –ë–î —Å—á–∏—Ç–∞–µ—Ç—Å—è –æ—Å–Ω–æ–≤–Ω–æ–π –≤—Å–µ–≥–¥–∞, –Ω–æ —Ä–∞–±–æ—Ç–∞–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ
        if supabase_client.is_connected():
            try:
                # –í –ë–î –º–æ–¥–µ–ª—å –ø–æ–∫–∞ –Ω–µ —Å–æ—Ö—Ä–∞–Ω—è–µ–º (–Ω–µ—Ç –ø–æ–ª—è –≤ —Å—Ö–µ–º–µ),
                # –Ω–æ –æ–Ω–∞ –µ—Å—Ç—å –≤ metadata —á–∞—Ç–∞ (–æ–±—â–∞—è –¥–ª—è —á–∞—Ç–∞)
                db_role = role
                if role == "system":
                    db_role = "assistant"
                    if not content.startswith("‚ö†Ô∏è") and not content.startswith("SYSTEM ALERT:"):
                        content = "SYSTEM ALERT: " + content

                asyncio.run(self._save_to_db(db_role, content, images, model=msg.get("model")))
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ –ë–î: {e}")

    async def _save_to_db(self, role: str, content: str, images: list = None, model: str = None):
        """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è –∏ –∫–∞—Ä—Ç–∏–Ω–æ–∫ –≤ Supabase –∏ S3."""
        try:
            if not self.db_chat_id:
                logger.warning("Supabase chat_id –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω, —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ")
                return

            # 1. –î–æ–±–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ
            msg_id = await supabase_client.add_message(
                chat_id=self.db_chat_id,
                role=role,
                content=content,
                model=model
            )
            
            if not msg_id:
                logger.warning("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ Supabase")
                return
            
            self._current_msg_id = msg_id # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–ª—è –ø—Ä–∏–≤—è–∑–∫–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞

            # 2. –ï—Å–ª–∏ –µ—Å—Ç—å –∫–∞—Ä—Ç–∏–Ω–∫–∏ - –∑–∞–≥—Ä—É–∂–∞–µ–º –≤ S3 –∏ —Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º
            if images:
                processed_paths = set()
                for img in images:
                    if not img.image_path or not Path(img.image_path).exists():
                        continue
                    
                    if img.image_path in processed_paths:
                        continue
                    processed_paths.add(img.image_path)
                        
                    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –ø—É—Ç—å –≤ S3
                    img_type = "zoom_crop" if img.is_zoom_request else "viewport"
                    filename = Path(img.image_path).name
                    s3_key = s3_storage.generate_s3_path(self.db_chat_id, img_type, filename)
                    
                    # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤ S3
                    try:
                        if getattr(img, 's3_url', None):
                            s3_url = img.s3_url
                        else:
                            s3_url = await s3_storage.upload_file(img.image_path, s3_key)
                        
                        if s3_url:
                            # –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º –≤ –ë–î (—ç—Ç–æ —Ç–∞–∫–∂–µ —Å–æ–∑–¥–∞–µ—Ç –∑–∞–ø–∏—Å—å –≤ storage_files)
                            await supabase_client.add_image_to_message(
                                chat_id=self.db_chat_id,
                                message_id=msg_id,
                                image_name=filename,
                                s3_path=s3_key,
                                s3_url=s3_url,
                                image_type=img_type,
                                description=img.description
                            )
                            
                            # –ü–†–û–í–ï–†–ö–ê: –ï—Å–ª–∏ —ç—Ç–æ –ø—Ä–µ–≤—å—é, –∑–∞–≥—Ä—É–∂–∞–µ–º —Ç–∞–∫–∂–µ –∏ –æ—Ä–∏–≥–∏–Ω–∞–ª (full)
                            if "_preview.png" in img.image_path:
                                full_path = img.image_path.replace("_preview.png", "_full.png")
                                if Path(full_path).exists():
                                    s3_full_key = s3_key.replace("_preview.png", "_full.png")
                                    await s3_storage.upload_file(full_path, s3_full_key)
                                    # –ü—Ä–æ—Å—Ç–æ —Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º –≤ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ —Ñ–∞–π–ª–æ–≤
                                    await supabase_client.register_file(
                                        user_id="default_user",
                                        source_type="llm_generated",
                                        filename=Path(full_path).name,
                                        storage_path=s3_full_key
                                    )
                        else:
                            logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å {filename} –≤ S3 (s3_url is None)")
                    except Exception as upload_err:
                        logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏/—Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è {filename}: {upload_err}")
                        
        except Exception as e:
            logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ _save_to_db: {e}", exc_info=True)

    def _save_gui_search_log(self, query, text_snippets, doc_index):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –ª–æ–≥ –ø–æ–∏—Å–∫–∞ –¥–ª—è GUI-–≤–µ—Ä—Å–∏–∏."""
        import datetime
        from .doc_index import tokenize_query
        
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        log_path = self.data_root / f"search_log_gui_{timestamp}.md"
        
        try:
            tokens = tokenize_query(query)
            relevant_pages = sorted(list(set(
                entry.page for entry in doc_index.images.values() 
                if entry.page is not None and any(t in entry.searchable_text().lower() for t in tokens)
            )))

            with open(log_path, "w", encoding="utf-8") as f:
                f.write(f"# –õ–æ–≥ –ø–æ–∏—Å–∫–∞ (GUI): {query}\n\n")
                
                f.write("## 1. –ó–∞–ø—Ä–æ—Å\n")
                f.write(f"{query}\n\n")
                
                f.write("## 2. –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞-—Å–∏–Ω–æ–Ω–∏–º—ã (—Ç–æ–∫–µ–Ω—ã)\n")
                f.write(f"{', '.join(tokens)}\n\n")
                
                f.write("## 3. –°–ø–∏—Å–æ–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –±–ª–æ–∫–æ–≤\n")
                if text_snippets:
                    for i, (chunk_id, text) in enumerate(text_snippets, 1):
                        f.write(f"### –ë–ª–æ–∫ {i} (ID: {chunk_id})\n")
                        f.write(f"{text}\n\n")
                else:
                    f.write("–¢–µ–∫—Å—Ç–æ–≤—ã–µ –±–ª–æ–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã.\n\n")
                
                f.write("## 4. –†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–∑ –∫–∞—Ç–∞–ª–æ–≥–∞\n")
                # –ò—â–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –≤ –∫–æ—Ç–æ—Ä—ã—Ö –µ—Å—Ç—å —Ç–æ–∫–µ–Ω—ã –∑–∞–ø—Ä–æ—Å–∞
                found_images = False
                for entry in doc_index.images.values():
                    if any(t in entry.searchable_text().lower() for t in tokens):
                        f.write(f"- **{entry.image_id}** (—Å—Ç—Ä. {entry.page})\n")
                        f.write(f"  - –û–ø–∏—Å–∞–Ω–∏–µ: {entry.content_summary}\n")
                        f.write(f"  - –°—Å—ã–ª–∫–∞: {entry.uri}\n")
                        found_images = True
                if not found_images:
                    f.write("–†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ –∫–∞—Ç–∞–ª–æ–≥–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã.\n")
                
                f.write("\n## 5. –†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã (–Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–æ–∏—Å–∫–∞ –ø–æ –∫–∞—Ç–∞–ª–æ–≥—É)\n")
                if relevant_pages:
                    f.write(f"{', '.join(map(str, relevant_pages))}\n")
                else:
                    f.write("–†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω—ã.\n")
            
            logger.info(f"–õ–æ–≥ –ø–æ–∏—Å–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {log_path.absolute()}")
            print(f"--- SEARCH LOG SAVED: {log_path.absolute()} ---")
            self.sig_log.emit(f"–õ–æ–≥ –ø–æ–∏—Å–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {log_path.name}")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –ª–æ–≥–∞ –ø–æ–∏—Å–∫–∞ (GUI): {e}")

    def _upload_images_to_s3(self, images: List):
        """–°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ–±–µ—Ä—Ç–∫–∞ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ —Å–ø–∏—Å–∫–∞ –∫–∞—Ä—Ç–∏–Ω–æ–∫ –≤ S3 –¥–ª—è LLM."""
        if not s3_storage.is_connected():
            return
            
        async def _upload_all():
            tasks = []
            for img in images:
                if img.image_path and Path(img.image_path).exists() and not getattr(img, 's3_url', None):
                    img_type = "zoom_crop" if getattr(img, 'is_zoom_request', False) else "viewport"
                    filename = Path(img.image_path).name
                    chat_id_for_path = self.db_chat_id or self.chat_id
                    s3_key = s3_storage.generate_s3_path(chat_id_for_path, img_type, filename)
                    tasks.append((img, s3_storage.upload_file(img.image_path, s3_key)))
            
            if not tasks:
                return

            # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
            for img, task in tasks:
                url = await task
                if url:
                    img.s3_url = url
                    logger.info(f"–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ {Path(img.image_path).name} –∑–∞–≥—Ä—É–∂–µ–Ω–æ –≤ S3: {url}")

        try:
            asyncio.run(_upload_all())
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –º–∞—Å—Å–æ–≤–æ–π –∑–∞–≥—Ä—É–∑–∫–∏ –≤ S3: {e}")

    def _upload_images_to_google_files(self, images: List, llm_client) -> None:
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ Google Files API –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ Gemini.
        –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç google_file_uri –≤ –∫–∞–∂–¥–æ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏.
        """
        for img in images:
            if not img.image_path or not Path(img.image_path).exists():
                continue
            
            if getattr(img, 'google_file_uri', None):
                continue  # –£–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω–æ
            
            try:
                display_name = Path(img.image_path).name
                uri = llm_client.upload_to_google_files(img.image_path, display_name)
                if uri:
                    img.google_file_uri = uri
                    self.sig_log.emit(f"‚Üí Google Files: {display_name}")
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {img.image_path} –≤ Google Files: {e}")

    def _update_tokens(self, tokens_to_add: int):
        """–î–æ–±–∞–≤–ª—è–µ—Ç —Ç–æ–∫–µ–Ω—ã –∫ –æ–±—â–µ–º—É —Å—á–µ—Ç—á–∏–∫—É –∏ –æ–±–Ω–æ–≤–ª—è–µ—Ç –ë–î."""
        self.total_tokens_used += tokens_to_add
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—á–µ—Ç—á–∏–∫ –≤ UI
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ª–∏–º–∏—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
        ctx_limit = 1_000_000  # 1M —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è Gemini
        remaining = max(0, ctx_limit - self.total_tokens_used)
        self.sig_usage.emit(self.total_tokens_used, remaining)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ë–î
        if self.db_chat_id and supabase_client.is_connected():
            try:
                asyncio.run(supabase_client.update_chat(
                    self.db_chat_id,
                    {"metadata": {"total_tokens": self.total_tokens_used}}
                ))
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Ç–æ–∫–µ–Ω–æ–≤ –≤ –ë–î: {e}")

    def _save_to_disk(self):
        history_path = self.chat_dir / "history.json"
        with open(history_path, "w", encoding="utf-8") as f:
            json.dump(self.chat_history_data, f, indent=2, ensure_ascii=False)
        self.sig_history_saved.emit(self.chat_id, self.query)

    def _log_full(self, header: str, content: object):
        try:
            with open(self.full_log_path, "a", encoding="utf-8") as f:
                f.write(f"\n{'='*20} {header} {'='*20}\n")
                if isinstance(content, (dict, list)):
                    f.write(json.dumps(content, indent=2, ensure_ascii=False))
                else:
                    f.write(str(content))
                f.write("\n")
        except Exception as e:
            logger.error(f"Failed to write full log: {e}")

    def _append_app_log(self, text: str):
        try:
            with open(self.full_log_path, "a", encoding="utf-8") as f:
                f.write(f"{text}\n")
        except: pass

    def _sanitize_messages_for_log(self, messages: list) -> list:
        """–û—á–∏—â–∞–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏—è –æ—Ç –¥–ª–∏–Ω–Ω—ã—Ö base64 –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è."""
        import copy
        sanitized = []
        for msg in messages:
            msg_copy = copy.deepcopy(msg)
            content = msg_copy.get("content", "")
            
            if isinstance(content, str):
                if len(content) > 5000:
                    msg_copy["content"] = f"<{len(content)} chars, truncated...>\n{content[:2000]}..."
            elif isinstance(content, list):
                new_content = []
                for part in content:
                    if isinstance(part, dict):
                        if part.get("type") == "text":
                            txt = part.get("text", "")
                            if len(txt) > 3000:
                                new_content.append({"type": "text", "text": f"<{len(txt)} chars truncated...>\n{txt[:1500]}..."})
                            else:
                                new_content.append(part)
                        elif part.get("type") == "image_url":
                            url = part.get("image_url", {}).get("url", "")
                            if url.startswith("data:"):
                                new_content.append({"type": "image_url", "image_url": {"url": f"<base64 image, {len(url)} chars>"}})
                            else:
                                new_content.append({"type": "image_url", "image_url": {"url": url[:200]}})
                        else:
                            new_content.append(part)
                    else:
                        new_content.append(part)
                msg_copy["content"] = new_content
            
            sanitized.append(msg_copy)
        return sanitized

    def run(self):
        try:
            # 0. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è (–ª–æ–≥ —Ñ–∞–π–ª–æ–≤)
            attached_files_info = "–ù–µ—Ç –ø—Ä–∏–∫—Ä–µ–ø–ª–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤."
            if self.md_files:
                attached_files_info = "–ü—Ä–∏–∫—Ä–µ–ø–ª–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã:\n" + "\n".join([str(Path(p).name) for p in self.md_files])
            elif Path(config.get_document_paths(self.data_root)[0]).exists():
                 p = Path(config.get_document_paths(self.data_root)[0])
                 attached_files_info = f"–ü—Ä–∏–∫—Ä–µ–ø–ª–µ–Ω–Ω—ã–π —Ñ–∞–π–ª (auto): {p.name}"

            self._log_full("–ò–ù–§–û–†–ú–ê–¶–ò–Ø –û –§–ê–ô–õ–ê–•", attached_files_info)
            self._log_full("–ó–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è", self.query)
            
            self.sig_log.emit(f"–°—Ç–∞—Ä—Ç —á–∞—Ç–∞ {self.chat_id}...")
            self._current_msg_id = None # –î–ª—è –ø—Ä–∏–≤—è–∑–∫–∏ –±–ª–æ–∫–æ–≤ –∫ —Å–æ–æ–±—â–µ–Ω–∏—é
            
            # 0. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —á–∞—Ç–∞ –≤ Supabase (—Ç–æ–ª—å–∫–æ –¥–ª—è –Ω–æ–≤—ã—Ö —á–∞—Ç–æ–≤)
            if not self.db_chat_id and supabase_client.is_connected():
                try:
                    title = self.query[:100]
                    self.db_chat_id = asyncio.run(supabase_client.create_chat(
                        title=title,
                        user_id="default_user",
                        description=self.query,
                        metadata={
                            "local_chat_id": self.chat_id,
                            "model": self.model,
                            "md_files": self.md_files
                        }
                    ))
                    if self.db_chat_id:
                        self.sig_log.emit(f"–ß–∞—Ç –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω –≤ –æ–±–ª–∞–∫–µ: {self.db_chat_id}")
                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —á–∞—Ç–∞ –≤ Supabase: {e}")

            image_processor = ImageProcessor(self.data_root)
            image_processor.temp_dir = self.images_dir
            
            self.current_step = 0

            def llm_log_callback(phase, data):
                log_data = data
                try:
                    # –°–∞–Ω–∏—Ç–∏–∑–∞—Ü–∏—è –¥–ª—è –ª–æ–≥–æ–≤: —Å–∫—Ä—ã–≤–∞–µ–º –æ–≥—Ä–æ–º–Ω—ã–π —Ç–µ–∫—Å—Ç —Ñ–∞–π–ª–æ–≤
                    if phase == "request" and isinstance(data, dict) and "messages" in data:
                        log_data = copy.deepcopy(data)
                        for msg in log_data.get("messages", []):
                            content = msg.get("content", "")
                            if isinstance(content, str) and len(content) > 2000:
                                msg["content"] = f"<{len(content)} chars truncated. See attached files list at the beginning of the log...>"
                            elif isinstance(content, list): # Multimodal
                                for part in content:
                                    if isinstance(part, dict) and part.get("type") == "text":
                                        txt = part.get("text", "")
                                        if len(txt) > 2000:
                                            part["text"] = f"<{len(txt)} chars truncated. See attached files list...>"
                                    elif isinstance(part, dict) and part.get("type") == "image_url":
                                        # –ú–æ–∂–Ω–æ —Ç–∞–∫–∂–µ —Å–æ–∫—Ä–∞—Ç–∏—Ç—å base64 –µ—Å–ª–∏ –æ–Ω —Ç–∞–º –µ—Å—Ç—å
                                        url = part.get("image_url", {}).get("url", "")
                                        if len(url) > 500:
                                            part["image_url"]["url"] = f"<{len(url)} chars base64 truncated>"
                except Exception as e:
                    logger.warning(f"–û—à–∏–±–∫–∞ —Å–∞–Ω–∏—Ç–∏–∑–∞—Ü–∏–∏ –ª–æ–≥–∞: {e}")

                if phase == "request":
                    self._log_full(f"–ó–∞–ø—Ä–æ—Å –∫ LLM ‚Ññ{self.current_step}", log_data)
                elif phase == "response":
                    self._log_full(f"–û—Ç–≤–µ—Ç–Ω—ã–π –∑–∞–ø—Ä–æ—Å –æ—Ç LLM ‚Ññ{self.current_step}", log_data)
                    self._append_app_log(f"\n{'='*20} –û—Ç–≤–µ—Ç –æ—Ç –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è ‚Ññ{self.current_step} {'='*20}")

            llm_client = LLMClient(model=self.model, data_root=self.data_root, log_callback=llm_log_callback)
            
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –¥–∏–∞–ª–æ–≥ —Å –∏—Å—Ç–æ—Ä–∏–µ–π, –µ—Å–ª–∏ –æ–Ω–∞ –µ—Å—Ç—å
            from .llm_client import load_analysis_prompt, load_zoom_prompt
            analysis_prompt = load_analysis_prompt(self.data_root)
            zoom_prompt = load_zoom_prompt(self.data_root)
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –Ω–∞—á–∞–ª—å–Ω—ã–π —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º—Ç: –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π -> –°–∏—Å—Ç–µ–º–Ω—ã–π 1 -> JSON -> HTML
            full_system_prompt = ""
            if self.user_prompt:
                full_system_prompt += f"–ò–ù–°–¢–†–£–ö–¶–ò–Ø –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø (–†–û–õ–¨): {self.user_prompt}\n\n"
            full_system_prompt += f"–°–ò–°–¢–ï–ú–ù–ê–Ø –ò–ù–°–¢–†–£–ö–¶–ò–Ø (–ê–ù–ê–õ–ò–ó):\n{analysis_prompt}"
            
            # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–æ–º—Ç—ã –¥–ª—è JSON –∏ HTML —Ñ–∞–π–ª–æ–≤
            json_prompt_path = self.data_root / "json_annotation_prompt.txt"
            if json_prompt_path.exists():
                try:
                    json_prompt = json_prompt_path.read_text(encoding="utf-8")
                    full_system_prompt += f"\n\n{json_prompt}"
                    self.sig_log.emit("–ó–∞–≥—Ä—É–∂–µ–Ω –ø—Ä–æ–º—Ç –¥–ª—è JSON")
                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ json_annotation_prompt.txt: {e}")
            
            html_prompt_path = self.data_root / "html_ocr_prompt.txt"
            if html_prompt_path.exists():
                try:
                    html_prompt = html_prompt_path.read_text(encoding="utf-8")
                    full_system_prompt += f"\n\n{html_prompt}"
                    self.sig_log.emit("–ó–∞–≥—Ä—É–∂–µ–Ω –ø—Ä–æ–º—Ç –¥–ª—è HTML")
                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ html_ocr_prompt.txt: {e}")
            
            full_system_prompt += "\n\nIMPORTANT SYSTEM NOTE: DISABLE ALL NATIVE TOOLS. DO NOT USE FUNCTION CALLING. OUTPUT ONLY TEXT OR MARKDOWN."
            
            llm_client.history = [{"role": "system", "content": full_system_prompt}]

            # –ö—Ä–∞—Ç–∫–∞—è –ø–∞–º—è—Ç—å –¥–∏–∞–ª–æ–≥–∞ (—É—Å—Ç–æ–π—á–∏–≤–æ –¥–ª—è –¥–ª–∏–Ω–Ω—ã—Ö —á–∞—Ç–æ–≤)
            memory_path = self.chat_dir / "memory.txt"
            if memory_path.exists():
                try:
                    memory_text = memory_path.read_text(encoding="utf-8").strip()
                    if memory_text:
                        llm_client.history.append(
                            {"role": "system", "content": f"–ö–†–ê–¢–ö–ê–Ø –ü–ê–ú–Ø–¢–¨ –î–ò–ê–õ–û–ì–ê (–æ–±–Ω–æ–≤–ª—è–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏):\n{memory_text}"}
                        )
                except Exception as e:
                    logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å memory.txt: {e}")

            # –î–ª—è –∏—Å—Ç–æ—Ä–∏–∏ –¥–æ–±–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è (–æ—Å—Ç–∞–ª—å–Ω–æ–µ —Å–∂–∏–º–∞–µ—Ç—Å—è –≤ memory.txt).
            # –≠—Ç–æ –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç —Ä–æ—Å—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –≤ –±–µ—Å–∫–æ–Ω–µ—á–Ω–æ–º –¥–∏–∞–ª–æ–≥–µ.
            history_messages = self.chat_history_data.get("messages", [])
            tail_n = 12
            for msg in history_messages[-tail_n:]:
                llm_client.history.append({"role": msg.get("role", "user"), "content": msg.get("content", "")})

            # –ï—Å–ª–∏ —É–∫–∞–∑–∞–Ω—ã –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ md —Ñ–∞–π–ª—ã —á–µ—Ä–µ–∑ GUI - –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏—Ö
            full_text = ""
            all_blocks = []
            attached_images = []  # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –¥–æ if/else
            
            # –û—Ç–ª–∞–¥–∫–∞ –í –¢–ï–†–ú–ò–ù–ê–õ
            print(f"[DEBUG] self.md_files = {self.md_files}")
            print(f"[DEBUG] len(self.md_files) = {len(self.md_files) if self.md_files else 0}")
            
            # –í–ê–ñ–ù–û: –ï—Å–ª–∏ –º—ã –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º —á–∞—Ç, –Ω–∞–º –≤—Å–µ —Ä–∞–≤–Ω–æ –Ω—É–∂–µ–Ω —Ç–µ–∫—Å—Ç –¥–æ–∫—É–º–µ–Ω—Ç–∞ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ.
            # –î–ª—è –≤–∞—Ä–∏–∞–Ω—Ç–∞ A –º—ã –ø—Ä–æ—Å—Ç–æ –∑–∞–Ω–æ–≤–æ —á–∏—Ç–∞–µ–º —Ñ–∞–π–ª—ã.
            if self.md_files:
                print(f"[DEBUG] –ù–∞—á–∏–Ω–∞—é –æ–±—Ä–∞–±–æ—Ç–∫—É {len(self.md_files)} —Ñ–∞–π–ª–æ–≤")
                self.sig_log.emit(f"–ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –≤—ã–±—Ä–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã: {len(self.md_files)}")
                
                for file_path_str in self.md_files:
                    try:
                        file_path = Path(file_path_str)
                        print(f"[DEBUG] –ß–∏—Ç–∞—é —Ñ–∞–π–ª: {file_path}")
                        print(f"[DEBUG] –§–∞–π–ª —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {file_path.exists()}")
                        self.sig_log.emit(f"–ß–∏—Ç–∞—é: {file_path}")
                        
                        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ñ–∞–π–ª –≤ S3 –∏ —Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º –≤ –ë–î
                        if self.db_chat_id:
                            try:
                                s3_doc_key = s3_storage.generate_s3_path(self.db_chat_id, "document", file_path.name)
                                s3_url = asyncio.run(s3_storage.upload_file(str(file_path), s3_doc_key))
                                
                                asyncio.run(supabase_client.register_file(
                                    user_id="default_user",
                                    source_type="user_upload",
                                    filename=file_path.name,
                                    storage_path=s3_doc_key,
                                    external_url=s3_url
                                ))
                            except Exception as e:
                                logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏/—Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏ —Ñ–∞–π–ª–∞: {e}")

                        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ñ–∞–π–ª –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞
                        print(f"[DEBUG] –í—ã–∑—ã–≤–∞—é FileProcessor.process_file...")
                        text, blocks, image = FileProcessor.process_file(file_path, self.db_chat_id)
                        
                        print(f"[DEBUG] FileProcessor –≤–µ—Ä–Ω—É–ª: text={len(text)} chars, blocks={len(blocks) if blocks else 0}, image={image is not None}")
                        
                        # –û—Ç–ª–∞–¥–∫–∞
                        self.sig_log.emit(f"  ‚Üí –ü–æ–ª—É—á–µ–Ω–æ —Ç–µ–∫—Å—Ç–∞: {len(text)} —Å–∏–º–≤–æ–ª–æ–≤, –±–ª–æ–∫–æ–≤: {len(blocks) if blocks else 0}")
                        
                        # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç
                        full_text += text
                        print(f"[DEBUG] full_text –ø–æ—Å–ª–µ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è: {len(full_text)} chars")
                        
                        # –î–æ–±–∞–≤–ª—è–µ–º –±–ª–æ–∫–∏ (–¥–ª—è .md —Ñ–∞–π–ª–æ–≤)
                        if blocks:
                            all_blocks.extend(blocks)
                            self.sig_log.emit(f"–ü—Ä–æ—á–∏—Ç–∞–Ω–æ –±–ª–æ–∫–æ–≤: {len(blocks)}")
                        
                        # –î–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π - –¥–æ–±–∞–≤–ª—è–µ–º –≤ —Å–ø–∏—Å–æ–∫ –¥–ª—è –ø–µ—Ä–µ–¥–∞—á–∏ –≤ LLM
                        if image:
                            # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ S3
                            if self.db_chat_id:
                                try:
                                    s3_img_key = s3_storage.generate_s3_path(
                                        self.db_chat_id, 
                                        "document", 
                                        file_path.name
                                    )
                                    s3_img_url = asyncio.run(s3_storage.upload_file(
                                        str(file_path), 
                                        s3_img_key,
                                        content_type=f"image/{file_path.suffix[1:]}"
                                    ))
                                    image.s3_url = s3_img_url
                                except Exception as e:
                                    logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ S3: {e}")
                            
                            attached_images.append(image)
                            self.sig_log.emit(f"–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–æ–±–∞–≤–ª–µ–Ω–æ: {file_path.name}")

                    except Exception as e:
                        print(f"[DEBUG] ‚ùå –ò–°–ö–õ–Æ–ß–ï–ù–ò–ï –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞: {e}")
                        import traceback
                        print(traceback.format_exc())
                        self.sig_log.emit(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è {file_path_str}: {e}")
                        import traceback
                        self.sig_log.emit(traceback.format_exc())
            else:
                # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –±–µ—Ä–µ–º result.md
                print(f"[DEBUG] –ò—â—É result.md –≤ {self.data_root}")
                self.sig_log.emit(f"–ò—â—É result.md –≤ {self.data_root}")
                markdown_path, _ = config.get_document_paths(self.data_root)
                print(f"[DEBUG] –ü—É—Ç—å: {markdown_path}, –°—É—â–µ—Å—Ç–≤—É–µ—Ç: {Path(markdown_path).exists()}")
                self.sig_log.emit(f"  –ü—É—Ç—å: {markdown_path}")
                self.sig_log.emit(f"  –°—É—â–µ—Å—Ç–≤—É–µ—Ç: {Path(markdown_path).exists()}")
                
                if Path(markdown_path).exists():
                    parser = MarkdownParser(markdown_path)
                    blocks = parser.parse()
                    all_blocks = blocks
                    
                    # –ó–∞–ø–æ–ª–Ω—è–µ–º full_text –∏–∑ –±–ª–æ–∫–æ–≤
                    for block in blocks:
                        full_text += block.text + "\n\n"
                    
                    # –ï—Å–ª–∏ –ø–∞—Ä—Å–µ—Ä –Ω–µ –∏–∑–≤–ª–µ–∫ —Ç–µ–∫—Å—Ç, —á–∏—Ç–∞–µ–º —Ñ–∞–π–ª –Ω–∞–ø—Ä—è–º—É—é
                    if not full_text.strip():
                        full_text = Path(markdown_path).read_text(encoding='utf-8')
                        self.sig_log.emit(f"  ‚Üí –ü—Ä–æ—á–∏—Ç–∞–Ω–æ {len(full_text)} —Å–∏–º–≤–æ–ª–æ–≤ –Ω–∞–ø—Ä—è–º—É—é")
                    else:
                        self.sig_log.emit(f"  ‚Üí –ò–∑–≤–ª–µ—á–µ–Ω–æ {len(full_text)} —Å–∏–º–≤–æ–ª–æ–≤ –∏–∑ {len(blocks)} –±–ª–æ–∫–æ–≤")
                else:
                    self.sig_log.emit(f"  ‚ö†Ô∏è result.md –ù–ï –ù–ê–ô–î–ï–ù!")
                    
                    # –ó–∞–≥—Ä—É–∂–∞–µ–º MD –≤ S3
                    if self.db_chat_id:
                        try:
                            s3_doc_key = s3_storage.generate_s3_path(self.db_chat_id, "document", Path(markdown_path).name)
                            s3_url = asyncio.run(s3_storage.upload_file(str(markdown_path), s3_doc_key))
                            asyncio.run(supabase_client.register_file(
                                user_id="default_user",
                                source_type="user_upload",
                                filename=Path(markdown_path).name,
                                storage_path=s3_doc_key,
                                external_url=s3_url
                            ))
                        except: pass

                    for block in blocks:
                        full_text += block.text + "\n\n"
                        
                        if self.db_chat_id:
                            try:
                                asyncio.run(supabase_client.add_search_result(
                                    chat_id=self.db_chat_id,
                                    message_id=None,
                                    block_id=block.block_id,
                                    block_text=block.text[:1000]
                                ))
                            except: pass
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –¥–∞–Ω–Ω—ã—Ö –¢–û–õ–¨–ö–û –µ—Å–ª–∏ –Ω–µ—Ç –ø—Ä–∏–∫—Ä–µ–ø–ª–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –≤–æ–æ–±—â–µ
            if not self.md_files and not attached_images:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –¥–µ—Ñ–æ–ª—Ç–Ω—ã–π result.md
                markdown_path, _ = config.get_document_paths(self.data_root)
                if not Path(markdown_path).exists():
                    # –û—Ç–ª–∞–¥–∫–∞
                    print(f"[DEBUG] ‚ùå –ù–µ—Ç –ø—Ä–∏–∫—Ä–µ–ø–ª–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –∏ result.md –Ω–µ –Ω–∞–π–¥–µ–Ω!")
                    print(f"[DEBUG]   md_files: {self.md_files}")
                    print(f"[DEBUG]   attached_images: {len(attached_images)}")
                    
                    self.sig_log.emit(f"‚ùå –û—à–∏–±–∫–∞: –Ω–µ—Ç —Ñ–∞–π–ª–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
                    self.sig_log.emit(f"  md_files: {self.md_files}")
                    self.sig_log.emit(f"  result.md path: {markdown_path}")
                    
                    raise ValueError("–í —á–∞—Ç–µ –Ω–µ—Ç –ø—Ä–∏–∫—Ä–µ–ø–ª–µ–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞. –ü—Ä–∏–∫—Ä–µ–ø–∏—Ç–µ —Ñ–∞–π–ª—ã (md, jpg, png, html, json) –∏–ª–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.")
            
            # –ï—Å–ª–∏ –µ—Å—Ç—å —Ç–æ–ª—å–∫–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –±–µ–∑ —Ç–µ–∫—Å—Ç–∞ ‚Äî —ç—Ç–æ –¥–æ–ø—É—Å—Ç–∏–º–æ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –∫—Ä–æ–ø PDF)

            # 1. –ß–∏—Ç–∞–µ–º –∏ —Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º MD —Ñ–∞–π–ª—ã
            full_md_text = ""
            all_blocks = []
            
            # –°–æ–±–∏—Ä–∞–µ–º —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
            files_to_process = []
            if self.md_files:
                files_to_process = self.md_files
            else:
                markdown_path, _ = config.get_document_paths(self.data_root)
                if Path(markdown_path).exists():
                    files_to_process = [str(markdown_path)]

            for md_path_str in files_to_process:
                try:
                    md_path = Path(md_path_str)
                    self.sig_log.emit(f"–û–±—Ä–∞–±–æ—Ç–∫–∞: {md_path.name}")
                    
                    # –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –≤ S3/DB
                    if self.db_chat_id:
                        try:
                            s3_doc_key = s3_storage.generate_s3_path(self.db_chat_id, "document", md_path.name)
                            s3_url = asyncio.run(s3_storage.upload_file(str(md_path), s3_doc_key))
                            asyncio.run(supabase_client.register_file(
                                user_id="default_user",
                                source_type="user_upload",
                                filename=md_path.name,
                                storage_path=s3_doc_key,
                                external_url=s3_url
                            ))
                        except: pass

                    # –ß—Ç–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞
                    if md_path.suffix.lower() == '.html':
                        llm_text, _ = HtmlOcrProcessor.process(md_path)
                        full_md_text += llm_text + "\n\n"
                    else:
                        text = md_path.read_text(encoding="utf-8")
                        full_md_text += text + "\n\n"
                    
                    # –ü–∞—Ä—Å–∏–Ω–≥ –±–ª–æ–∫–æ–≤ –¥–ª—è RAG –∏ –ø–æ–∏—Å–∫–∞
                    if md_path.suffix.lower() == '.md':
                        parser = MarkdownParser(md_path)
                        all_blocks.extend(parser.parse())
                except Exception as e:
                    self.sig_log.emit(f"–û—à–∏–±–∫–∞ —Ñ–∞–π–ª–∞ {md_path_str}: {e}")

            if not full_md_text.strip():
                # –¢—Ä–µ–±—É–µ–º —Ç–µ–∫—Å—Ç –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏
                if not full_text.strip():
                    raise ValueError("–ù–µ—Ç —Ç–µ–∫—Å—Ç–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞.")
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º full_text –∏–∑ –ø–µ—Ä–≤–æ–≥–æ –ø—Ä–æ—Ö–æ–¥–∞
                full_md_text = full_text
            
            # –ï—Å–ª–∏ –Ω–µ—Ç —Ç–µ–∫—Å—Ç–∞, –Ω–æ –µ—Å—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è ‚Äî —ç—Ç–æ —Ä–µ–∂–∏–º "—Ç–æ–ª—å–∫–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"
            only_images_mode = (not full_md_text.strip() and attached_images)
            
            if only_images_mode:
                self.sig_log.emit("üì∑ –†–µ–∂–∏–º: –¢–æ–ª—å–∫–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (–±–µ–∑ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞)")
                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—é, —Å—Ä–∞–∑—É –ø–µ—Ä–µ–¥–∞—ë–º –∑–∞–ø—Ä–æ—Å + –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ LLM
                context = f"–ó–ê–ü–†–û–° –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø:\n{self.query}\n\n–û—Ç–≤–µ—Ç—å –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–∏–∫—Ä–µ–ø–ª—ë–Ω–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π."
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
                self.save_message("user", self.query, images=None)
                
                # –ü–µ—Ä–µ–¥–∞—ë–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ LLM
                llm_client.add_user_message(context, images=attached_images)
                
                # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç (JSON)
                response_json = llm_client.get_response()
                
                # –ü–∞—Ä—Å–∏–º JSON –∏ –∏–∑–≤–ª–µ–∫–∞–µ–º answer_markdown
                try:
                    response_data = json.loads(response_json)
                    answer_text = response_data.get("answer_markdown", "")
                    if not answer_text or not answer_text.strip():
                        answer_text = "‚ö†Ô∏è –ú–æ–¥–µ–ª—å –Ω–µ –≤–µ—Ä–Ω—É–ª–∞ –æ—Ç–≤–µ—Ç (answer_markdown –ø—É—Å—Ç–æ–π)"
                except json.JSONDecodeError as e:
                    answer_text = f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON: {e}\n\n–°—ã—Ä–æ–π –æ—Ç–≤–µ—Ç:\n{response_json}"
                
                self.sig_message.emit("assistant", answer_text, self.model)
                self.save_message("assistant", answer_text, images=None)
                
                self.sig_finished.emit()
                return

            # ===== –†–ï–ñ–ò–ú FLASH + PRO =====
            if self.model == "flash+pro":
                self.sig_log.emit("üîÑ –†–µ–∂–∏–º: Flash + Pro (–¥–≤—É—Ö—ç—Ç–∞–ø–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞)")
                self._run_flash_pro_mode(
                    full_md_text=full_md_text,
                    files_to_process=files_to_process,
                    attached_images=attached_images if 'attached_images' in locals() else [],
                    all_blocks=all_blocks
                )
                return

            # ===== –ü–û–î–ì–û–¢–û–í–ö–ê –ö–û–ù–¢–ï–ö–°–¢–ê =====
            
            from .doc_index import build_index, strip_json_blocks, ImageCatalogEntry
            from .json_annotation_processor import JsonAnnotationProcessor
            doc_index = build_index(full_md_text)
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–∑ JSON –∏ HTML —Ñ–∞–π–ª–æ–≤ –≤ –∫–∞—Ç–∞–ª–æ–≥
            for md_path_str in files_to_process:
                md_path = Path(md_path_str)
                suffix = md_path.suffix.lower()
                
                if suffix == '.json':
                    try:
                        _, annotation = JsonAnnotationProcessor.process(md_path)
                        if annotation:
                            for img_block in annotation.image_blocks:
                                # –î–æ–±–∞–≤–ª—è–µ–º ID –∏–∑ JSON –≤ –∫–∞—Ç–∞–ª–æ–≥ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
                                entry = ImageCatalogEntry(
                                    image_id=img_block.block_id,
                                    page=img_block.page_number,
                                    uri=img_block.crop_url or "",
                                    content_summary=img_block.content_summary or "",
                                    detailed_description=img_block.detailed_description or "",
                                    clean_ocr_text=img_block.ocr_text or "",
                                    key_entities=img_block.key_entities or []
                                )
                                doc_index.images[img_block.block_id] = entry
                            self.sig_log.emit(f"–î–æ–±–∞–≤–ª–µ–Ω–æ {len(annotation.image_blocks)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏–∑ JSON –≤ –∫–∞—Ç–∞–ª–æ–≥")
                    except Exception as e:
                        logger.error(f"–û—à–∏–±–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏–∑ JSON {md_path}: {e}")
                
                elif suffix == '.html':
                    try:
                        _, document = HtmlOcrProcessor.process(md_path)
                        if document:
                            for img_block in document.image_blocks:
                                entry = ImageCatalogEntry(
                                    image_id=img_block.block_id,
                                    page=img_block.page_number,
                                    uri=img_block.crop_url or "",
                                    content_summary=img_block.content_summary or "",
                                    detailed_description=img_block.detailed_description or "",
                                    clean_ocr_text=img_block.ocr_text or "",
                                    key_entities=img_block.key_entities or [],
                                    sheet_name=img_block.sheet_name or ""
                                )
                                doc_index.images[img_block.block_id] = entry
                            self.sig_log.emit(f"–î–æ–±–∞–≤–ª–µ–Ω–æ {len(document.image_blocks)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏–∑ HTML –≤ –∫–∞—Ç–∞–ª–æ–≥")
                    except Exception as e:
                        logger.error(f"–û—à–∏–±–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏–∑ HTML {md_path}: {e}")
                
                elif suffix == '.md':
                    # –ü–∞—Ä—Å–∏–Ω–≥ –Ω–æ–≤–æ–≥–æ MD —Ñ–æ—Ä–º–∞—Ç–∞ (_document.md)
                    try:
                        md_image_blocks = FileProcessor.parse_md_image_blocks(md_path)
                        for img_block in md_image_blocks:
                            entry = ImageCatalogEntry(
                                image_id=img_block.block_id,
                                page=img_block.page_number,
                                uri=img_block.crop_url or "",
                                content_summary=img_block.content_summary or "",
                                detailed_description=img_block.detailed_description or "",
                                clean_ocr_text=img_block.ocr_text or "",
                                key_entities=img_block.key_entities or [],
                                sheet_name=img_block.sheet_name or "",
                                local_path=img_block.local_path or ""
                            )
                            doc_index.images[img_block.block_id] = entry
                        if md_image_blocks:
                            self.sig_log.emit(f"–î–æ–±–∞–≤–ª–µ–Ω–æ {len(md_image_blocks)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏–∑ MD –≤ –∫–∞—Ç–∞–ª–æ–≥")
                    except Exception as e:
                        logger.error(f"–û—à–∏–±–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏–∑ MD {md_path}: {e}")
            
            tail_n = 12 # –ù–∞—á–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –∏—Å—Ç–æ—Ä–∏–∏
            context = ""
            
            # –¶–∏–∫–ª —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ —Å –ø–æ–ø—ã—Ç–∫–æ–π –≤–ø–∏—Ö–Ω—É—Ç—å –º–∞–∫—Å–∏–º—É–º
            while tail_n >= 0:
                # –û—á–∏—â–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é –¥–ª—è –Ω–æ–≤–æ–π –ø–æ–ø—ã—Ç–∫–∏
                llm_client.history = [{"role": "system", "content": full_system_prompt}]
                
                if memory_path.exists():
                    try:
                        mem = memory_path.read_text(encoding="utf-8").strip()
                        if mem: llm_client.history.append({"role": "system", "content": f"–ö–†–ê–¢–ö–ê–Ø –ü–ê–ú–Ø–¢–¨: {mem}"})
                    except: pass
                
                # –î–æ–±–∞–≤–ª—è–µ–º —Ö–≤–æ—Å—Ç –∏—Å—Ç–æ—Ä–∏–∏
                history_messages = self.chat_history_data.get("messages", [])
                for msg in history_messages[-(tail_n if tail_n > 0 else 0):] if tail_n > 0 else []:
                    llm_client.history.append({"role": msg.get("role", "user"), "content": msg.get("content", "")})

                # –†–µ–∂–∏–º full_md (RAG —É–¥–∞–ª—ë–Ω)
                self.sig_log.emit(f"–†–µ–∂–∏–º: –ü–æ–ª–Ω—ã–π MD (history_n={tail_n})...")
                
                doc_text = strip_json_blocks(full_md_text)
                # –ö—ç—à–∏—Ä—É–µ–º –¥–æ–∫—É–º–µ–Ω—Ç –¥–ª—è Gemini –µ—Å–ª–∏ –µ—â–µ –Ω–µ –∫—ç—à–∏—Ä–æ–≤–∞–Ω
                if not llm_client.current_cache:
                    llm_client.set_document_context(doc_text)
                
                img_entries = sorted(doc_index.images.values(), key=lambda e: ((e.page or 0), e.image_id))
                catalog_text = "\n".join([f"- {e.image_id} (—Å—Ç—Ä. {e.page}): {e.content_summary[:150]}" for e in img_entries])
                
                # –ï—Å–ª–∏ –∫—ç—à –∞–∫—Ç–∏–≤–µ–Ω, –Ω–µ —à–ª–µ–º —Ç–µ–∫—Å—Ç –¥–æ–∫—É–º–µ–Ω—Ç–∞ –ø–æ–≤—Ç–æ—Ä–Ω–æ –≤ —Å–æ–æ–±—â–µ–Ω–∏—è—Ö
                doc_prefix = "" if llm_client.current_cache else f"–ü–û–õ–ù–´–ô –¢–ï–ö–°–¢ –î–û–ö–£–ú–ï–ù–¢–ê:\n{doc_text}\n\n"
                
                context = (
                    f"{doc_prefix}"
                    f"–ö–ê–¢–ê–õ–û–ì –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–ô:\n{catalog_text}\n\n"
                    f"–ó–ê–ü–†–û–° –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø:\n{self.query}\n\n"
                    f"–ò—Å–ø–æ–ª—å–∑—É–π tool=request_images –∏ tool=zoom –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –≥—Ä–∞—Ñ–∏–∫–æ–π."
                )

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –≤–ª–µ–∑–∞–µ—Ç –ª–∏
                temp_history = llm_client.history + [{"role": "user", "content": context}]
                est = llm_client.build_context_report(temp_history, max_tokens=config.MAX_TOKENS)
                
                if not est.get("will_overflow"):
                    self.sig_log.emit(f"OK: –ü—Ä–æ–º–ø—Ç ~{est.get('prompt_tokens_est')} —Ç–æ–∫–µ–Ω–æ–≤.")
                    break
                
                if tail_n == 0:
                    # –ü–µ—Ä–µ–ø–æ–ª–Ω–µ–Ω–∏–µ –¥–∞–∂–µ –±–µ–∑ –∏—Å—Ç–æ—Ä–∏–∏ ‚Äî –æ—à–∏–±–∫–∞ (RAG fallback —É–¥–∞–ª—ë–Ω)
                    raise ValueError("–î–æ–∫—É–º–µ–Ω—Ç —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –º–æ–¥–µ–ª–∏. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ä–µ–∂–∏–º flash+pro –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ —Å–∂–∞—Ç–∏—è.")
                
                tail_n -= 3 # –£–º–µ–Ω—å—à–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é –∏ –ø—Ä–æ–±—É–µ–º —Å–Ω–æ–≤–∞
                self.sig_log.emit(f"‚ö†Ô∏è –ü–µ—Ä–µ–ø–æ–ª–Ω–µ–Ω–∏–µ. –°–æ–∫—Ä–∞—â–∞—é –∏—Å—Ç–æ—Ä–∏—é –¥–æ {tail_n}...")

            self.save_message("user", self.query, images=None)
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞ –≤ –ë–î (–ø–∞–∫–µ—Ç–Ω–æ)
            if self.db_chat_id and hasattr(self, '_current_msg_id') and self._current_msg_id:
                bulk_data = [{"chat_id": self.db_chat_id, "message_id": self._current_msg_id, "block_id": b.block_id, "block_text": b.text[:1000]} for b in all_blocks]
                if bulk_data:
                    try: asyncio.run(supabase_client.add_search_results_bulk(bulk_data))
                    except: pass

            # –ü–µ—Ä–µ–¥–∞—ë–º –ø—Ä–∏–∫—Ä–µ–ø–ª—ë–Ω–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (–µ—Å–ª–∏ –µ—Å—Ç—å) –≤–º–µ—Å—Ç–µ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
            llm_client.add_user_message(context, images=attached_images if 'attached_images' in locals() else None)
            
            step = 0
            max_steps = 10
            # –ö–∞–∫–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (full/preview) —É–∂–µ –±—ã–ª–∏ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω—ã –º–æ–¥–µ–ª–∏ –≤ —ç—Ç–æ–º –∑–∞–ø—É—Å–∫–µ.
            # –ù—É–∂–Ω–æ, —á—Ç–æ–±—ã ZOOM –≤—ã–ø–æ–ª–Ω—è–ª—Å—è —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ —Ç–æ–≥–æ, –∫–∞–∫ –º–æ–¥–µ–ª—å —É–≤–∏–¥–µ–ª–∞ –±–∞–∑–æ–≤—É—é –∫–∞—Ä—Ç–∏–Ω–∫—É.
            sent_image_ids = set()
            
            # –û—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –æ–¥–Ω–∏—Ö –∏ —Ç–µ—Ö –∂–µ –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö ID
            last_missing_ids = set()
            missing_repeat_count = 0
            max_missing_repeats = 3
            
            while step < max_steps and self.is_running:
                step += 1
                self.current_step = step
                self.sig_log.emit(f"–®–∞–≥ {step}...")

                # –ü—Ä–æ–≥–Ω–æ–∑ –ø–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É
                try:
                    est = llm_client.last_prompt_estimate or llm_client.build_context_report(llm_client.history, max_tokens=config.MAX_TOKENS)
                    if est and est.get("will_overflow"):
                        self.sig_log.emit("‚ö†Ô∏è –†–∏—Å–∫ –ø–µ—Ä–µ–ø–æ–ª–Ω–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –Ω–∞ —Ç–µ–∫—É—â–µ–º —à–∞–≥–µ!")
                except: pass
                
                try:
                    response_json = llm_client.get_response()
                except Exception as e:
                    if "context_length" in str(e).lower():
                        err = "–ö—Ä–∏—Ç–∏—á–µ—Å–∫–æ–µ –ø–µ—Ä–µ–ø–æ–ª–Ω–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Ä–µ–∂–∏–º RAG –∏–ª–∏ –¥—Ä—É–≥—É—é –º–æ–¥–µ–ª—å."
                        self.sig_log.emit(f"‚ùå {err}")
                        self.save_message("system", err)
                        raise ValueError(err)
                    raise e
                
                # –ü–∞—Ä—Å–∏–º JSON –æ—Ç–≤–µ—Ç
                try:
                    response_data = json.loads(response_json)
                except json.JSONDecodeError as e:
                    err = f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON –æ—Ç –º–æ–¥–µ–ª–∏: {e}"
                    self.sig_log.emit(err)
                    self.sig_message.emit("assistant", f"{err}\n\n–°—ã—Ä–æ–π –æ—Ç–≤–µ—Ç:\n{response_json[:500]}", self.model)
                    self.save_message("assistant", err)
                    break
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º answer_markdown –¥–ª—è –ø–æ–∫–∞–∑–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
                answer_markdown = response_data.get("answer_markdown", "")
                needs_more_evidence = response_data.get("needs_more_evidence", False)
                followup_images = response_data.get("followup_images", [])
                followup_zooms = response_data.get("followup_zooms", [])
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –æ—Ç–≤–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é (–µ—Å–ª–∏ –µ—Å—Ç—å)
                if answer_markdown and answer_markdown.strip():
                    self.sig_message.emit("assistant", answer_markdown, self.model)
                    self.save_message("assistant", answer_markdown)
                
                # –§–∞–∫—Ç –ø–æ usage (–∞–Ω–∞–ª–∏–∑)
                try:
                    usage = llm_client.last_usage
                    if isinstance(usage, dict) and usage.get("prompt_tokens") is not None:
                        pt = usage.get("prompt_tokens")
                        ct = usage.get("completion_tokens")
                        tt = usage.get("total_tokens")
                        ctx = llm_client.get_model_context_length()
                        rem = (ctx - pt) if (isinstance(ctx, int) and isinstance(pt, int)) else None
                        self.sig_log.emit(
                            f"[–ö–æ–Ω—Ç–µ–∫—Å—Ç/—Ñ–∞–∫—Ç][–∞–Ω–∞–ª–∏–∑] prompt={pt}, completion={ct}, total={tt}, "
                            f"–ª–∏–º–∏—Ç={ctx if ctx is not None else '–Ω–µ–∏–∑–≤.'}, –æ—Å—Ç–∞—Ç–æ–∫={rem if rem is not None else '–Ω–µ–∏–∑–≤.'}"
                        )
                        if isinstance(tt, int) and tt > 0:
                            self._update_tokens(tt)
                except Exception:
                    pass
                
                # –§–ª–∞–≥, —É–∫–∞–∑—ã–≤–∞—é—â–∏–π, —á—Ç–æ –±—ã–ª –≤—ã–ø–æ–ª–Ω–µ–Ω –∫–∞–∫–æ–π-—Ç–æ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç (images, zoom) –∏ –Ω—É–∂–Ω–æ –ø—Ä–æ–¥–æ–ª–∂–∞—Ç—å —Ü–∏–∫–ª
                tools_executed = False

                # 1) –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∑–∞–ø—Ä–æ—Å—ã –Ω–∞ –ø–æ–¥–≥—Ä—É–∑–∫—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏–∑ followup_images
                if followup_images and needs_more_evidence:
                    # –°–æ–±–∏—Ä–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ id
                    req_ids = []
                    for rid in followup_images:
                        rid = str(rid).strip()
                        if rid.endswith(".pdf"):
                            rid = rid[:-4]
                        if rid and rid not in req_ids:
                            req_ids.append(rid)

                    info_msg = f"üñºÔ∏è –ó–∞–ø—Ä–æ—à–µ–Ω—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {', '.join(req_ids[:15])}{' ...' if len(req_ids) > 15 else ''}"
                    self.sig_log.emit(f"LLM –∑–∞–ø—Ä–æ—Å–∏–ª–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {req_ids}")
                    self._append_app_log(f"–ó–∞–ø—Ä–æ—à–µ–Ω—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {req_ids}")
                    self.sig_message.emit("assistant", info_msg, self.model)
                    self.save_message("assistant", info_msg)

                    downloaded_imgs = []
                    missing_ids = []
                    for rid in req_ids:
                        if not self.is_running:
                            return
                        entry = doc_index.images.get(rid)
                        if not entry:
                            missing_ids.append(rid)
                            continue
                        self.sig_log.emit(f"–°–∫–∞—á–∏–≤–∞–Ω–∏–µ (–ø–æ id): {rid}")
                        self._append_app_log(f"–°–∫–∞—á–∏–≤–∞–Ω–∏–µ (–ø–æ id): {rid}")
                        
                        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ª–æ–∫–∞–ª—å–Ω—ã–π –ø—É—Ç—å –µ—Å–ª–∏ –Ω–µ—Ç URI
                        image_source = entry.uri if entry.uri else entry.local_path
                        if not image_source:
                            self._append_app_log(f"  ‚ö†Ô∏è –ù–µ—Ç –∏—Å—Ç–æ—á–Ω–∏–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {rid}")
                            missing_ids.append(rid)
                            continue
                        
                        # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ (–ø—Ä–µ–≤—å—é + –≤–æ–∑–º–æ–∂–Ω—ã–µ –∞–≤—Ç–æ-–∑—É–º—ã)
                        crops = image_processor.download_and_process_pdf(image_source, image_id=rid)
                        if crops:
                            downloaded_imgs.extend(crops)
                            sent_image_ids.add(str(rid))
                            for c in crops:
                                if c.image_path:
                                    self.sig_image.emit(c.image_path, f"Image ID: {rid}")

                    if missing_ids:
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –ø–æ–≤—Ç–æ—Ä—è—é—Ç—Å—è –ª–∏ —Ç–µ –∂–µ ID
                        current_missing = set(missing_ids)
                        if current_missing == last_missing_ids:
                            missing_repeat_count += 1
                            if missing_repeat_count >= max_missing_repeats:
                                err_msg = f"‚ö†Ô∏è –ú–æ–¥–µ–ª—å {max_missing_repeats} —Ä–∞–∑–∞ –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ—Ç –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ ID: {', '.join(sorted(current_missing)[:10])}. –ü—Ä–µ—Ä—ã–≤–∞—é —Ü–∏–∫–ª."
                                self.sig_log.emit(err_msg)
                                self._append_app_log(err_msg)
                                
                                # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ–º
                                final_msg = (
                                    f"{err_msg}\n\n"
                                    f"**–î–æ—Å—Ç—É–ø–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ –∫–∞—Ç–∞–ª–æ–≥–µ:**\n"
                                    f"{chr(10).join([f'- {img_id}' for img_id in sorted(doc_index.images.keys())[:20]])}"
                                    f"{chr(10)}... –≤—Å–µ–≥–æ {len(doc_index.images)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π"
                                )
                                self.sig_message.emit("system", final_msg, None)
                                self.save_message("system", final_msg)
                                break  # –í—ã—Ö–æ–¥–∏–º –∏–∑ —Ü–∏–∫–ª–∞
                        else:
                            last_missing_ids = current_missing
                            missing_repeat_count = 1
                        
                        warn = f"‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω–æ –≤ –∫–∞—Ç–∞–ª–æ–≥–µ: {', '.join(missing_ids[:10])}{' ...' if len(missing_ids) > 10 else ''}"
                        self.sig_log.emit(warn)
                        self._append_app_log(warn)
                        self.save_message("assistant", warn)

                    if downloaded_imgs:
                        # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤ S3 –¥–ª—è LLM (—á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å 503 –∏ –ª–∏–º–∏—Ç–æ–≤ –Ω–∞ —Ä–∞–∑–º–µ—Ä –∑–∞–ø—Ä–æ—Å–∞)
                        self._upload_images_to_s3(downloaded_imgs)

                        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ
                        msg_text = "üñºÔ∏è –ó–∞–≥—Ä—É–∂–µ–Ω—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø–æ –∑–∞–ø—Ä–æ—Å—É –º–æ–¥–µ–ª–∏."
                        
                        # –¢–∞–∫ –∫–∞–∫ –º—ã –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Å—Å—ã–ª–∫–∏, –º–æ–∂–µ–º –ø–µ—Ä–µ–¥–∞—Ç—å –≤—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π
                        self.save_message("assistant", msg_text, images=downloaded_imgs)
                        llm_client.add_user_message(msg_text, images=downloaded_imgs)
                        
                        tools_executed = True
                    else:
                        # –ù–µ—á–µ–≥–æ –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å –º–æ–¥–µ–ª–∏ ‚Äî –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º, —á—Ç–æ–±—ã –æ–Ω–∞ –º–æ–≥–ª–∞ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –∑–∞–ø—Ä–æ—Å
                        llm_client.add_user_message("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∑–∞–ø—Ä–æ—à–µ–Ω–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è. –ü–æ–ø—Ä–æ–±—É–π —É–∫–∞–∑–∞—Ç—å –¥—Ä—É–≥–∏–µ image_ids –∏–∑ –∫–∞—Ç–∞–ª–æ–≥–∞.")
                        tools_executed = True

                # 2) –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∑–∞–ø—Ä–æ—Å—ã zoom –∏–∑ followup_zooms
                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º followup_zooms –≤ ZoomRequest –æ–±—ä–µ–∫—Ç—ã –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
                zoom_reqs = []
                if followup_zooms and needs_more_evidence:
                    for fz in followup_zooms:
                        zoom_req = ZoomRequest(
                            image_id=fz.get("image_id"),
                            coords_norm=fz.get("coords_norm"),
                            coords_px=None,
                            reason=fz.get("reason", "–î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑")
                        )
                        zoom_reqs.append(zoom_req)
                
                print(f"[GUI_AGENT] Zoom –∑–∞–ø—Ä–æ—Å–æ–≤: {len(zoom_reqs)}")
                
                if zoom_reqs:
                    tools_executed = True
                    self._append_app_log(f"LLM Tool Call: Zoom ({len(zoom_reqs)} requests)")
                    
                    # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–µ—Ç–∞–ª–µ–π –∑—É–º–∞ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
                    for i, zr in enumerate(zoom_reqs):
                        is_full = False
                        try:
                            if zr.coords_norm:
                                x1, y1, x2, y2 = zr.coords_norm
                                if x1 <= 0.01 and y1 <= 0.01 and x2 >= 0.99 and y2 >= 0.99:
                                    is_full = True
                        except: pass

                        type_str = "Full Image" if is_full else "Crop"
                        detail_log = f"Request #{i+1} ({type_str}): ImageID={zr.image_id}, "
                        if zr.coords_norm:
                            detail_log += f"Coords(Norm)={zr.coords_norm}, "
                        if zr.coords_px:
                            detail_log += f"Coords(Px)={zr.coords_px}, "
                        detail_log += f"Reason={zr.reason}"
                        self._append_app_log(detail_log)

                    # –ü—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∑—É–º–∞ –¥–æ–±–∞–≤–ª—è–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º—Ç 2 (ZOOM –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏)
                    llm_client.history.append({"role": "system", "content": f"–¢–ï–•–ù–ò–ß–ï–°–ö–ê–Ø –ò–ù–°–¢–†–£–ö–¶–ò–Ø –ü–û ZOOM:\n{zoom_prompt}"})
                    
                    # 0) –ï—Å–ª–∏ –º–æ–¥–µ–ª—å –ø—Ä–æ—Å–∏—Ç ZOOM –¥–æ —Ç–æ–≥–æ, –∫–∞–∫ —É–≤–∏–¥–µ–ª–∞ –±–∞–∑–æ–≤—É—é –∫–∞—Ä—Ç–∏–Ω–∫—É (full/preview),
                    # –∏–ª–∏ –ø—Ä–æ—Å–∏—Ç "zoom –Ω–∞ –≤–µ—Å—å –ª–∏—Å—Ç" (coords_norm 0..1), –º—ã –ù–ï –≤—ã–ø–æ–ª–Ω—è–µ–º zoom.
                    # –í–º–µ—Å—Ç–æ —ç—Ç–æ–≥–æ —Å–Ω–∞—á–∞–ª–∞ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –±–∞–∑–æ–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏ –ø—Ä–æ—Å–∏–º —É—Ç–æ—á–Ω–∏—Ç—å –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã.
                    need_base_ids = []
                    need_refine_ids = []

                    def _is_full_frame_norm(coords_norm) -> bool:
                        try:
                            if not coords_norm or len(coords_norm) != 4:
                                return False
                            x1, y1, x2, y2 = coords_norm
                            # –¢–æ–ª–µ—Ä–∞–Ω—Å, —á—Ç–æ–±—ã –æ—Ç–ª–∞–≤–ª–∏–≤–∞—Ç—å [0,0,1,1] –∏ –±–ª–∏–∑–∫–∏–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã.
                            return (x1 <= 0.01 and y1 <= 0.01 and x2 >= 0.99 and y2 >= 0.99)
                        except Exception:
                            return False

                    # –°–æ–±–∏—Ä–∞–µ–º, –∫–∞–∫–∏–µ image_id —Ç—Ä–µ–±—É—é—Ç –±–∞–∑–æ–≤–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏/–∏–ª–∏ —É—Ç–æ—á–Ω–µ–Ω–∏—è –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç.
                    for zr in zoom_reqs:
                        img_id = getattr(zr, "image_id", None)
                        if isinstance(img_id, str) and img_id.endswith(".pdf"):
                            img_id = img_id[:-4]
                            zr.image_id = img_id

                        if not isinstance(img_id, str) or not img_id.strip():
                            continue

                        if img_id not in sent_image_ids:
                            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–Ω–æ –ª–∏ —Å–∫–∞—á–∏–≤–∞—Ç—å –±–∞–∑–æ–≤—É—é –∫–∞—Ä—Ç–∏–Ω–∫—É
                            # –ù–æ –ù–ï –¥–æ–±–∞–≤–ª—è–µ–º –≤ need_base_ids, –µ—Å–ª–∏ –º—ã —É–∂–µ —Å–æ–±–∏—Ä–∞–µ–º—Å—è –¥–µ–ª–∞—Ç—å zoom —Å–µ–π—á–∞—Å.
                            # –í–º–µ—Å—Ç–æ —ç—Ç–æ–≥–æ –ø—Ä–æ—Å—Ç–æ —É–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ –æ–Ω–∞ —Å–∫–∞—á–∞–Ω–∞, —á—Ç–æ–±—ã process_zoom_request —Å—Ä–∞–±–æ—Ç–∞–ª.
                            
                            # –õ–æ–≥–∏–∫–∞ need_base_ids –±—ã–ª–∞ –Ω—É–∂–Ω–∞ –¥–ª—è —Ç–æ–≥–æ, —á—Ç–æ–±—ã –ü–û–ö–ê–ó–ê–¢–¨ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é –∏ –º–æ–¥–µ–ª–∏
                            # –æ–±—â–∏–π –ø–ª–∞–Ω –ü–ï–†–ï–î —Ç–µ–º, –∫–∞–∫ –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å –∑—É–º—ã. –≠—Ç–æ –ø–æ–ª–µ–∑–Ω–æ.
                            # –ù–æ continue –ø—Ä–µ—Ä—ã–≤–∞–µ—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑—É–º–æ–≤.
                            # –ò–∑–º–µ–Ω–∏–º —Ç–∞–∫: –µ—Å–ª–∏ –Ω—É–∂–Ω—ã –±–∞–∑–æ–≤—ã–µ –∫–∞—Ä—Ç–∏–Ω–∫–∏, –º—ã –∏—Ö —Å–∫–∞—á–∏–≤–∞–µ–º, –ü–û–ö–ê–ó–´–í–ê–ï–ú,
                            # –Ω–æ –ù–ï –ø—Ä–µ—Ä—ã–≤–∞–µ–º —Ü–∏–∫–ª, –∞ –∏–¥–µ–º –¥–∞–ª—å—à–µ –∫ –∑—É–º–∞–º.
                            
                            if img_id not in need_base_ids:
                                need_base_ids.append(img_id)

                        # –ó–∞–ø—Ä–µ—â–∞–µ–º "zoom –Ω–∞ –≤–µ—Å—å –ª–∏—Å—Ç" ‚Äî —ç—Ç–æ –ø–æ —Å—É—Ç–∏ request_images.
                        if _is_full_frame_norm(getattr(zr, "coords_norm", None)) or (not zr.coords_norm and not zr.coords_px):
                            if img_id not in need_refine_ids:
                                need_refine_ids.append(img_id)

                    # –ï—Å–ª–∏ –Ω–µ –±—ã–ª–æ –±–∞–∑–æ–≤–æ–π –∫–∞—Ä—Ç–∏–Ω–∫–∏ ‚Äî –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –µ—ë.
                    # –†–∞–Ω—å—à–µ —Ç—É—Ç –±—ã–ª continue, –∫–æ—Ç–æ—Ä—ã–π –ø—Ä–µ—Ä—ã–≤–∞–ª –∑—É–º—ã. –£–±–∏—Ä–∞–µ–º –µ–≥–æ.
                    if need_base_ids:
                        base_imgs = []
                        missing_ids = []
                        for img_id in need_base_ids:
                            if not self.is_running:
                                return
                            entry = doc_index.images.get(img_id)
                            if not entry:
                                missing_ids.append(img_id)
                                continue
                            self.sig_log.emit(f"–ü–æ–¥–≥—Ä—É–∂–∞—é –±–∞–∑–æ–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–µ—Ä–µ–¥ zoom: {img_id}")
                            self._append_app_log(f"–ü–æ–¥–≥—Ä—É–∂–∞—é –±–∞–∑–æ–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–µ—Ä–µ–¥ zoom: {img_id}")
                            
                            # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ (–ø—Ä–µ–≤—å—é + –≤–æ–∑–º–æ–∂–Ω—ã–µ –∞–≤—Ç–æ-–∑—É–º—ã)
                            crops = image_processor.download_and_process_pdf(entry.uri, image_id=img_id)
                            if crops:
                                base_imgs.extend(crops)
                                sent_image_ids.add(img_id)
                                for c in crops:
                                    if c.image_path:
                                        self.sig_image.emit(c.image_path, f"Image ID: {img_id}")

                        if missing_ids:
                            warn = f"‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω–æ –≤ –∫–∞—Ç–∞–ª–æ–≥–µ (–¥–ª—è zoom): {', '.join(missing_ids[:10])}{' ...' if len(missing_ids) > 10 else ''}"
                            self.sig_log.emit(warn)
                            self.save_message("assistant", warn)

                        if base_imgs:
                            note = (
                                "üñºÔ∏è –ü–æ–¥–≥—Ä—É–∂–µ–Ω—ã –±–∞–∑–æ–≤—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (full/preview). "
                                "–ù–∏–∂–µ —Å–ª–µ–¥—É—é—Ç –∑–∞–ø—Ä–æ—à–µ–Ω–Ω—ã–µ –¥–µ—Ç–∞–ª—å–Ω—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã (Zoom)."
                            )
                            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ —Å –±–∞–∑–æ–≤—ã–º–∏ –∫–∞—Ä—Ç–∏–Ω–∫–∞–º–∏
                            self.save_message("assistant", note, images=base_imgs)
                            # –î–æ–±–∞–≤–ª—è–µ–º –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç –º–æ–¥–µ–ª–∏, —á—Ç–æ–±—ã –æ–Ω–∞ –∑–Ω–∞–ª–∞, —á—Ç–æ –æ–Ω–∏ –µ—Å—Ç—å
                            llm_client.add_user_message(note, images=base_imgs)
                            
                            # –£–ë–†–ê–õ–ò continue: –∏–¥–µ–º –≤—ã–ø–æ–ª–Ω—è—Ç—å –∑—É–º—ã —Å—Ä–∞–∑—É –∂–µ!
                            # continue 

                    # –ï—Å–ª–∏ –±–∞–∑–æ–≤—ã–µ –∫–∞—Ä—Ç–∏–Ω–∫–∏ —É–∂–µ –±—ã–ª–∏, –Ω–æ zoom –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π ‚Äî –ø—Ä–æ—Å–∏–º —É—Ç–æ—á–Ω–∏—Ç—å –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã.
                    if need_refine_ids:
                        msg = (
                            "‚ö†Ô∏è –ù—É–∂–Ω—ã —É—Ç–æ—á–Ω—ë–Ω–Ω—ã–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –¥–ª—è zoom. "
                            "–£–∫–∞–∂–∏ `coords_norm` –∫–∞–∫ —Ä–∞–º–∫—É –≤–æ–∫—Ä—É–≥ –∏–Ω—Ç–µ—Ä–µ—Å—É—é—â–µ–π –∑–æ–Ω—ã (–º–µ–Ω—å—à–µ, —á–µ–º –≤–µ—Å—å –ª–∏—Å—Ç)."
                        )
                        self.save_message("assistant", msg)
                        llm_client.add_user_message(msg, images=None)
                        continue

                    zoom_crops = []
                    for i, zr in enumerate(zoom_reqs):
                        zoom_msg = f"üîÑ *Zoom [{i+1}/{len(zoom_reqs)}]:* {zr.reason}"
                        self.sig_log.emit(zoom_msg)
                        self._append_app_log(zoom_msg)
                        self.sig_message.emit("assistant", zoom_msg, self.model)

                        # –ï—Å–ª–∏ –º–æ–¥–µ–ª—å –ø—Ä–æ—Å–∏—Ç zoom –ø–æ image_id, –Ω–æ –±–∞–∑–æ–≤–∞—è –∫–∞—Ä—Ç–∏–Ω–∫–∞ –µ—â—ë –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞ ‚Äî
                        # –ø–æ–¥–≥—Ä—É–∂–∞–µ–º –µ—ë –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–æ –∫–∞—Ç–∞–ª–æ–≥—É (—É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å).
                        try:
                            img_id = getattr(zr, "image_id", None)
                            if isinstance(img_id, str) and img_id:
                                # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è: –∏–Ω–æ–≥–¥–∞ –º–æ–¥–µ–ª—å –ø—Ä–∏—Å—ã–ª–∞–µ—Ç id —Å .pdf
                                if img_id.endswith(".pdf"):
                                    img_id = img_id[:-4]
                                    zr.image_id = img_id
                                if img_id not in getattr(image_processor, "_image_cache", {}):
                                    entry = doc_index.images.get(img_id)
                                    if entry:
                                        self.sig_log.emit(f"–ü–æ–¥–≥—Ä—É–∂–∞—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è zoom: {img_id}")
                                        image_processor.download_and_process_pdf(entry.uri, image_id=img_id)
                        except Exception as e:
                            self.sig_log.emit(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è zoom: {e}")
                        
                        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∏–º—è —Ñ–∞–π–ª–∞. –ï—Å–ª–∏ –∫—Ä–æ–ø –±—É–¥–µ—Ç –±–æ–ª—å—à–µ 2000px, –ø–æ–º–µ—á–∞–µ–º –∫–∞–∫ preview.
                        prefix = "zoom_step"
                        try:
                            if img_id and img_id in image_processor._image_sizes:
                                w_full, h_full = image_processor._image_sizes[img_id]
                                cw, ch = 0, 0
                                if zr.coords_norm:
                                    nx1, ny1, nx2, ny2 = zr.coords_norm
                                    cw = abs(nx2 - nx1) * w_full
                                    ch = abs(ny2 - ny1) * h_full
                                elif zr.coords_px:
                                    x1, y1, x2, y2 = zr.coords_px
                                    cw = abs(x2 - x1)
                                    ch = abs(y2 - y1)
                                
                                if max(cw, ch) > 2000:
                                    scale_factor = max(cw, ch) / 2000
                                    prefix = f"zoom_preview_{scale_factor:.1f}_step"
                        except: pass

                        zoom_crop = image_processor.process_zoom_request(
                            zr,
                            output_path=self.images_dir / f"{prefix}_{step}_{i}.png"
                        )
                        
                        if zoom_crop:
                            zoom_crops.append(zoom_crop)
                            self._append_app_log(f"Zoom {i+1} OK: {zoom_crop.image_path}")
                            if zoom_crop.image_path:
                                self.sig_image.emit(zoom_crop.image_path, f"Zoom {i+1}")
                        else:
                            self.sig_log.emit(f"–û—à–∏–±–∫–∞ Zoom {i+1}")
                            self._append_app_log(f"–û—à–∏–±–∫–∞ Zoom {i+1}")

                    if zoom_crops:
                        # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤ S3 –¥–ª—è LLM
                        self._upload_images_to_s3(zoom_crops)
                        
                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é –∏ –ë–î –û–î–ù–ò–ú —Å–æ–æ–±—â–µ–Ω–∏–µ–º —Å–æ –≤—Å–µ–º–∏ –∫–∞—Ä—Ç–∏–Ω–∫–∞–º–∏
                        # –¢–µ–∫—Å—Ç —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π —É–∂–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤—ã—à–µ (–≤ response), –∑–¥–µ—Å—å —Ç–æ–ª—å–∫–æ —Ñ–∏–∫—Å–∏—Ä—É–µ–º —Ñ–∞–∫—Ç Zoom –∏ –∫–∞—Ä—Ç–∏–Ω–∫–∏.
                        self.save_message("assistant", "üîé –í—ã–ø–æ–ª–Ω–µ–Ω Zoom (—Å–º. –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è)", images=zoom_crops)
                        llm_client.add_user_message("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã Zoom:", images=zoom_crops)
                    else:
                        self.sig_log.emit("–û—à–∏–±–∫–∞ Zoom: –Ω–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã.")
                        self._append_app_log("–û—à–∏–±–∫–∞ Zoom: –Ω–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã.")
                        self.save_message("assistant", "‚ö†Ô∏è –û—à–∏–±–∫–∞ Zoom: –Ω–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã.")
                
                if not tools_executed:
                    self._append_app_log("–§–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç –ø–æ–ª—É—á–µ–Ω.")
                    # –û—Ç–≤–µ—Ç —É–∂–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ –Ω–∞—á–∞–ª–µ —Ü–∏–∫–ª–∞
                    
                    # –û–±–Ω–æ–≤–ª—è–µ–º –∫—Ä–∞—Ç–∫—É—é –ø–∞–º—è—Ç—å –¥–∏–∞–ª–æ–≥–∞ (–¥–ª—è —É—Å—Ç–æ–π—á–∏–≤—ã—Ö –¥–ª–∏–Ω–Ω—ã—Ö —á–∞—Ç–æ–≤)
                    try:
                        prev_mem = ""
                        if memory_path.exists():
                            prev_mem = memory_path.read_text(encoding="utf-8").strip()
                        new_mem = llm_client.update_memory_summary(prev_mem, self.query, response)
                        if new_mem:
                            memory_path.write_text(new_mem.strip(), encoding="utf-8")
                    except Exception as e:
                        logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±–Ω–æ–≤–∏—Ç—å –ø–∞–º—è—Ç—å –¥–∏–∞–ª–æ–≥–∞: {e}")

                    self.sig_finished.emit()
                    return

            if self.is_running:
                err = "–õ–∏–º–∏—Ç —à–∞–≥–æ–≤."
                self.sig_error.emit(err)
                self.save_message("system", err)
                
        except Exception as e:
            logger.error(f"Error: {e}", exc_info=True)
            self.sig_error.emit(str(e))
            self.sig_finished.emit()

    def stop(self):
        self.is_running = False

    def _run_flash_pro_mode(self, full_md_text: str, files_to_process: list, 
                            attached_images: list, all_blocks: list):
        """
        –î–≤—É—Ö—ç—Ç–∞–ø–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞: Flash —Å–æ–±–∏—Ä–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç, Pro –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç.
        """
        from .doc_index import build_index, strip_json_blocks, ImageCatalogEntry
        from .json_annotation_processor import JsonAnnotationProcessor
        from .llm_client import LLMClient, load_flash_extractor_prompt, load_analysis_prompt
        from .image_processor import ImageProcessor
        
        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞—á–∞–ª–∞ Flash+Pro —Ä–µ–∂–∏–º–∞
        self._log_full("–†–ï–ñ–ò–ú FLASH+PRO", {
            "query": self.query,
            "files": [str(f) for f in files_to_process],
            "attached_images_count": len(attached_images) if attached_images else 0
        })
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
        image_processor = ImageProcessor(self.data_root)
        image_processor.temp_dir = self.images_dir
        
        llm_client = LLMClient(model="gemini-3-flash-preview", data_root=self.data_root)
        
        # –°—Ç—Ä–æ–∏–º –∏–Ω–¥–µ–∫—Å –¥–æ–∫—É–º–µ–Ω—Ç–∞
        doc_index = build_index(full_md_text)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–∑ JSON –∏ HTML —Ñ–∞–π–ª–æ–≤
        for md_path_str in files_to_process:
            md_path = Path(md_path_str)
            suffix = md_path.suffix.lower()
            
            if suffix == '.json':
                try:
                    _, annotation = JsonAnnotationProcessor.process(md_path)
                    if annotation:
                        for img_block in annotation.image_blocks:
                            entry = ImageCatalogEntry(
                                image_id=img_block.block_id,
                                page=img_block.page_number,
                                uri=img_block.crop_url or "",
                                content_summary=img_block.content_summary or "",
                                detailed_description=img_block.detailed_description or "",
                                clean_ocr_text=img_block.ocr_text or "",
                                key_entities=img_block.key_entities or []
                            )
                            doc_index.images[img_block.block_id] = entry
                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏–∑ JSON: {e}")
            
            elif suffix == '.html':
                try:
                    _, document = HtmlOcrProcessor.process(md_path)
                    if document:
                        for img_block in document.image_blocks:
                            entry = ImageCatalogEntry(
                                image_id=img_block.block_id,
                                page=img_block.page_number,
                                uri=img_block.crop_url or "",
                                content_summary=img_block.content_summary or "",
                                detailed_description=img_block.detailed_description or "",
                                clean_ocr_text=img_block.ocr_text or "",
                                key_entities=img_block.key_entities or [],
                                sheet_name=img_block.sheet_name or ""
                            )
                            doc_index.images[img_block.block_id] = entry
                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏–∑ HTML: {e}")
            
            elif suffix == '.md':
                # –ü–∞—Ä—Å–∏–Ω–≥ –Ω–æ–≤–æ–≥–æ MD —Ñ–æ—Ä–º–∞—Ç–∞ (_document.md)
                try:
                    md_image_blocks = FileProcessor.parse_md_image_blocks(md_path)
                    for img_block in md_image_blocks:
                        entry = ImageCatalogEntry(
                            image_id=img_block.block_id,
                            page=img_block.page_number,
                            uri=img_block.crop_url or "",
                            content_summary=img_block.content_summary or "",
                            detailed_description=img_block.detailed_description or "",
                            clean_ocr_text=img_block.ocr_text or "",
                            key_entities=img_block.key_entities or [],
                            sheet_name=img_block.sheet_name or "",
                            local_path=img_block.local_path or ""
                        )
                        doc_index.images[img_block.block_id] = entry
                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏–∑ MD: {e}")
        
        # ===== –≠–¢–ê–ü 1: FLASH –≠–ö–°–¢–†–ê–ö–¢–û–† =====
        self.sig_log.emit("üìã –≠—Ç–∞–ø 1: Flash –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç...")
        self.sig_message.emit("system", "üîç –≠—Ç–∞–ø 1: Flash –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é –∏ —Å–æ–±–∏—Ä–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç...", None)
        
        flash_prompt = load_flash_extractor_prompt(self.data_root)
        doc_text = strip_json_blocks(full_md_text)
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –û–ë–û–ì–ê–©–Å–ù–ù–´–ô –∫–∞—Ç–∞–ª–æ–≥ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è Flash
        img_entries = sorted(doc_index.images.values(), key=lambda e: ((e.page or 0), e.image_id))
        catalog_lines = []
        for e in img_entries:
            # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: sheet_name (–Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –ª–∏—Å—Ç–∞) > content_summary
            description = e.sheet_name if e.sheet_name else e.content_summary
            # –î–æ–±–∞–≤–ª—è–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å—É—â–Ω–æ—Å—Ç–∏ –µ—Å–ª–∏ –µ—Å—Ç—å
            entities_str = ""
            if e.key_entities:
                entities_str = f" | –°—É—â–Ω–æ—Å—Ç–∏: {', '.join(e.key_entities[:8])}"
            catalog_lines.append(f"- {e.image_id} (—Å—Ç—Ä. {e.page}): {description[:200]}{entities_str}")
        catalog_text = "\n".join(catalog_lines)
        
        flash_context = f"""–î–û–ö–£–ú–ï–ù–¢:
{doc_text}

–ö–ê–¢–ê–õ–û–ì –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–ô:
{catalog_text}

–ó–ê–ü–†–û–° –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø:
{self.query}

–ò–∑–≤–ª–µ–∫–∏ –í–°–ï —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ —ç—Ç–æ—Ç –∑–∞–ø—Ä–æ—Å."""
        
        flash_messages = [
            {"role": "system", "content": flash_prompt},
            {"role": "user", "content": flash_context}
        ]
        
        # –õ–æ–≥–∏—Ä—É–µ–º –Ω–∞—á–∞–ª—å–Ω—ã–π –∑–∞–ø—Ä–æ—Å Flash
        self._log_full("FLASH: –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç", flash_prompt)
        self._log_full("FLASH: –ù–∞—á–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç (—É—Å–µ—á–µ–Ω–æ)", flash_context[:10000] + "..." if len(flash_context) > 10000 else flash_context)
        
        # –°–æ–±–∏—Ä–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏—Ç–µ—Ä–∞—Ç–∏–≤–Ω–æ
        collected_images = []  # ViewportCrop
        collected_zooms = []   # ViewportCrop
        sent_image_ids = set()
        max_flash_steps = 5
        flash_step = 0
        extracted_context = None
        
        while flash_step < max_flash_steps and self.is_running:
            flash_step += 1
            self.sig_log.emit(f"Flash —à–∞–≥ {flash_step}/{max_flash_steps}...")
            self._append_app_log(f"\n{'='*20} FLASH –®–ê–ì {flash_step} {'='*20}")
            
            # –õ–æ–≥–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å –∫ Flash
            self._log_full(f"FLASH #{flash_step}: –ó–∞–ø—Ä–æ—Å", self._sanitize_messages_for_log(flash_messages))
            
            try:
                flash_response = llm_client.call_flash_model(
                    flash_messages,
                    response_schema=FLASH_EXTRACTOR_SCHEMA
                )
            except Exception as e:
                self.sig_log.emit(f"–û—à–∏–±–∫–∞ Flash: {e}")
                self._log_full(f"FLASH #{flash_step}: –û—à–∏–±–∫–∞", str(e))
                break
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—á–µ—Ç—á–∏–∫ —Ç–æ–∫–µ–Ω–æ–≤ –ø–æ—Å–ª–µ –≤—ã–∑–æ–≤–∞ Flash
            try:
                usage = llm_client.last_usage
                if isinstance(usage, dict) and usage.get("total_tokens"):
                    tt = usage.get("total_tokens")
                    self._update_tokens(tt)
                    self.sig_log.emit(f"Flash —à–∞–≥ {flash_step}: –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ {tt} —Ç–æ–∫–µ–Ω–æ–≤")
            except Exception as e:
                logger.debug(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±–Ω–æ–≤–∏—Ç—å —Ç–æ–∫–µ–Ω—ã Flash: {e}")
            
            # –õ–æ–≥–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç Flash
            self._log_full(f"FLASH #{flash_step}: –û—Ç–≤–µ—Ç", flash_response)
            
            # –î–æ–±–∞–≤–ª—è–µ–º –æ—Ç–≤–µ—Ç Flash –≤ –∏—Å—Ç–æ—Ä–∏—é
            flash_messages.append({"role": "model", "content": flash_response})
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –≥–æ—Ç–æ–≤ –ª–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç
            extracted_context = llm_client.parse_flash_context(flash_response)
            if extracted_context:
                self.sig_log.emit("‚úÖ Flash —Å–æ–±—Ä–∞–ª –∫–æ–Ω—Ç–µ–∫—Å—Ç")
                break
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∑–∞–ø—Ä–æ—Å—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
            img_reqs = llm_client.parse_image_requests(flash_response)
            if img_reqs:
                self._log_full(f"FLASH #{flash_step}: –ó–∞–ø—Ä–æ—Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π", [{"image_ids": r.image_ids, "reason": r.reason} for r in img_reqs])
                
                downloaded_imgs = []
                for r in img_reqs:
                    for rid in r.image_ids:
                        if rid in sent_image_ids:
                            continue
                        entry = doc_index.images.get(rid)
                        if not entry:
                            self._append_app_log(f"  ‚ö†Ô∏è –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ: {rid}")
                            continue
                        self.sig_log.emit(f"Flash –∑–∞–ø—Ä–æ—Å–∏–ª–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {rid}")
                        self._append_app_log(f"  üì• –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {rid}")
                        
                        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ª–æ–∫–∞–ª—å–Ω—ã–π –ø—É—Ç—å –µ—Å–ª–∏ –Ω–µ—Ç URI
                        image_source = entry.uri if entry.uri else entry.local_path
                        if not image_source:
                            self._append_app_log(f"  ‚ö†Ô∏è –ù–µ—Ç –∏—Å—Ç–æ—á–Ω–∏–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {rid}")
                            continue
                        crops = image_processor.download_and_process_pdf(image_source, image_id=rid)
                        if crops:
                            downloaded_imgs.extend(crops)
                            sent_image_ids.add(rid)
                            for c in crops:
                                if c.image_path:
                                    self.sig_image.emit(c.image_path, f"Flash: {rid}")
                
                if downloaded_imgs:
                    # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤ Google Files API –¥–ª—è Gemini
                    self._upload_images_to_google_files(downloaded_imgs, llm_client)
                    # Fallback –Ω–∞ S3 –µ—Å–ª–∏ Google Files –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª
                    self._upload_images_to_s3(downloaded_imgs)
                    collected_images.extend(downloaded_imgs)
                    self._log_full(f"FLASH #{flash_step}: –ó–∞–≥—Ä—É–∂–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π", len(downloaded_imgs))
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç Flash
                    img_content = [{"type": "text", "text": "–ó–∞–≥—Ä—É–∂–µ–Ω—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:"}]
                    for img in downloaded_imgs:
                        # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: Google Files URI, –ø–æ—Ç–æ–º S3 URL
                        img_url = getattr(img, 'google_file_uri', None) or img.s3_url
                        if img_url:
                            img_content.append({
                                "type": "image_url",
                                "image_url": {"url": img_url}
                            })
                    flash_messages.append({"role": "user", "content": img_content})
                    continue
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∑–∞–ø—Ä–æ—Å—ã –∑—É–º–æ–≤
            zoom_reqs = llm_client.parse_zoom_request(flash_response)
            if zoom_reqs:
                self._log_full(f"FLASH #{flash_step}: –ó–∞–ø—Ä–æ—Å—ã ZOOM", [
                    {"image_id": zr.image_id, "coords_norm": zr.coords_norm, "coords_px": zr.coords_px, "reason": zr.reason} 
                    for zr in zoom_reqs
                ])
                
                zoom_crops = []
                for i, zr in enumerate(zoom_reqs):
                    self.sig_log.emit(f"Flash –∑–∞–ø—Ä–æ—Å–∏–ª–∞ zoom: {zr.reason[:50]}")
                    self._append_app_log(f"  üîç ZOOM #{i+1}: {zr.image_id}, coords_norm={zr.coords_norm}, reason={zr.reason[:80]}")
                    
                    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
                    img_id = getattr(zr, "image_id", None)
                    if isinstance(img_id, str) and img_id:
                        if img_id.endswith(".pdf"):
                            img_id = img_id[:-4]
                            zr.image_id = img_id
                        if img_id not in getattr(image_processor, "_image_cache", {}):
                            entry = doc_index.images.get(img_id)
                            if entry:
                                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ª–æ–∫–∞–ª—å–Ω—ã–π –ø—É—Ç—å –µ—Å–ª–∏ –Ω–µ—Ç URI
                                image_source = entry.uri if entry.uri else entry.local_path
                                if image_source:
                                    image_processor.download_and_process_pdf(image_source, image_id=img_id)
                    
                    zoom_crop = image_processor.process_zoom_request(
                        zr,
                        output_path=self.images_dir / f"flash_zoom_{flash_step}_{i}.png"
                    )
                    
                    if zoom_crop:
                        zoom_crops.append(zoom_crop)
                        self._append_app_log(f"    ‚úÖ ZOOM —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {zoom_crop.image_path}")
                        if zoom_crop.image_path:
                            self.sig_image.emit(zoom_crop.image_path, f"Flash zoom {i+1}")
                    else:
                        self._append_app_log(f"    ‚ùå ZOOM –Ω–µ —É–¥–∞–ª—Å—è")
                
                if zoom_crops:
                    # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤ Google Files API –¥–ª—è Gemini
                    self._upload_images_to_google_files(zoom_crops, llm_client)
                    # Fallback –Ω–∞ S3
                    self._upload_images_to_s3(zoom_crops)
                    collected_zooms.extend(zoom_crops)
                    self._log_full(f"FLASH #{flash_step}: –í—ã–ø–æ–ª–Ω–µ–Ω–æ ZOOM", len(zoom_crops))
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º –∑—É–º—ã –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç Flash
                    zoom_content = [{"type": "text", "text": "–†–µ–∑—É–ª—å—Ç–∞—Ç—ã ZOOM:"}]
                    for zc in zoom_crops:
                        # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: Google Files URI, –ø–æ—Ç–æ–º S3 URL
                        img_url = getattr(zc, 'google_file_uri', None) or zc.s3_url
                        if img_url:
                            zoom_content.append({
                                "type": "image_url",
                                "image_url": {"url": img_url}
                            })
                    flash_messages.append({"role": "user", "content": zoom_content})
                    continue
            
            # –ï—Å–ª–∏ –Ω–µ—Ç –∑–∞–ø—Ä–æ—Å–æ–≤ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤, –ø—Ä–æ—Å–∏–º Flash –∑–∞–≤–µ—Ä—à–∏—Ç—å
            flash_messages.append({
                "role": "user", 
                "content": "–ï—Å–ª–∏ —Ç—ã —Å–æ–±—Ä–∞–ª –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞, –≤–µ—Ä–Ω–∏ JSON —Å–æ status: 'ready'. –ò–Ω–∞—á–µ –∑–∞–ø—Ä–æ—Å–∏ –Ω—É–∂–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–ª–∏ –∑—É–º—ã."
            })
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
        flash_context_data = {
            "flash_steps": flash_step,
            "extracted_context": {
                "relevant_text_chunks": extracted_context.relevant_text_chunks if extracted_context else [],
                "relevant_images": extracted_context.relevant_images if extracted_context else [],
                "flash_reasoning": extracted_context.flash_reasoning if extracted_context else ""
            },
            "collected_images": [img.image_path for img in collected_images if img.image_path],
            "collected_zooms": [z.image_path for z in collected_zooms if z.image_path],
            "flash_messages_history": self._sanitize_messages_for_log(flash_messages)
        }
        
        # –õ–æ–≥–∏—Ä—É–µ–º –∏—Ç–æ–≥–∏ Flash
        self._append_app_log(f"\n{'='*20} FLASH –ò–¢–û–ì–ò {'='*20}")
        self._log_full("FLASH: –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞", {
            "steps": flash_step,
            "collected_images": len(collected_images),
            "collected_zooms": len(collected_zooms),
            "text_chunks": len(extracted_context.relevant_text_chunks) if extracted_context else 0,
            "reasoning": extracted_context.flash_reasoning[:500] if extracted_context and extracted_context.flash_reasoning else ""
        })
        
        flash_context_path = self.chat_dir / "flash_context.json"
        try:
            with open(flash_context_path, "w", encoding="utf-8") as f:
                json.dump(flash_context_data, f, indent=2, ensure_ascii=False)
            self.sig_log.emit(f"–°–æ—Ö—Ä–∞–Ω–µ–Ω –∫–æ–Ω—Ç–µ–∫—Å—Ç Flash: {flash_context_path.name}")
            self._append_app_log(f"üìÑ –°–æ—Ö—Ä–∞–Ω–µ–Ω: {flash_context_path}")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è flash_context.json: {e}")
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è Pro
        analysis_prompt = load_analysis_prompt(self.data_root)
        
        # –°–æ–∑–¥–∞—ë–º –∏–Ω–¥–µ–∫—Å –±–ª–æ–∫–æ–≤ –ø–æ ID –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞
        blocks_by_id = {}
        for block in all_blocks:
            if block.block_id:
                blocks_by_id[block.block_id] = block
        
        # –°–æ–±–∏—Ä–∞–µ–º –ü–û–õ–ù–´–ï —Ç–µ–∫—Å—Ç—ã –±–ª–æ–∫–æ–≤ –ø–æ block_id –æ—Ç Flash
        text_blocks_str = ""
        blocks_found = 0
        added_block_ids = set()  # –ß—Ç–æ–±—ã –Ω–µ –¥–æ–±–∞–≤–ª—è—Ç—å –¥—É–±–ª–∏–∫–∞—Ç—ã
        
        if extracted_context and extracted_context.relevant_blocks:
            for block_ref in extracted_context.relevant_blocks:
                block_id = block_ref.get("block_id")
                reason = block_ref.get("reason", "")
                
                # –ò—â–µ–º –±–ª–æ–∫ –ø–æ ID
                if block_id and block_id in blocks_by_id and block_id not in added_block_ids:
                    block = blocks_by_id[block_id]
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º page_hint –∏–∑ –±–ª–æ–∫–∞ (–ø–∞—Ä—Å–∏—Ç—Å—è –∏–∑ MD)
                    page = block.page_hint if block.page_hint else "?"
                    text_blocks_str += f"\n### –ë–õ–û–ö [{block_id}] (–°—Ç—Ä. {page})\n"
                    if reason:
                        text_blocks_str += f"*–ü—Ä–∏—á–∏–Ω–∞ –≤—ã–±–æ—Ä–∞: {reason}*\n"
                    text_blocks_str += f"{block.text}\n"
                    blocks_found += 1
                    added_block_ids.add(block_id)
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º —Å–≤—è–∑–∞–Ω–Ω—ã–µ –±–ª–æ–∫–∏ (‚ÜíID)
                    for linked_id in block.linked_block_ids:
                        if linked_id in blocks_by_id and linked_id not in added_block_ids:
                            linked_block = blocks_by_id[linked_id]
                            linked_page = linked_block.page_hint if linked_block.page_hint else "?"
                            text_blocks_str += f"\n### –ë–õ–û–ö [{linked_id}] (–°—Ç—Ä. {linked_page}, —Å–≤—è–∑–∞–Ω —Å {block_id})\n"
                            text_blocks_str += f"{linked_block.text}\n"
                            blocks_found += 1
                            added_block_ids.add(linked_id)
                            
                elif block_id and block_id not in added_block_ids:
                    # –ë–ª–æ–∫ –Ω–µ –Ω–∞–π–¥–µ–Ω, –Ω–æ –µ—Å—Ç—å content –∏–∑ —Å—Ç–∞—Ä–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞
                    content = block_ref.get("content", "")
                    page = block_ref.get("page", "?")
                    if content:
                        text_blocks_str += f"\n### –ë–õ–û–ö [{block_id}] (–°—Ç—Ä. {page})\n{content}\n"
                        blocks_found += 1
                        added_block_ids.add(block_id)
        
        self.sig_log.emit(f"Pro –ø–æ–ª—É—á–∏—Ç {blocks_found} —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –±–ª–æ–∫–æ–≤")
        
        # –í—ã–≤–æ–¥–∏–º —Å–æ–±—Ä–∞–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –≤ —á–∞—Ç (–≠—Ç–∞–ø 1 –∑–∞–≤–µ—Ä—à—ë–Ω)
        flash_summary_parts = []
        flash_summary_parts.append("üìã **–ö–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è Pro (—Å–æ–±—Ä–∞–Ω Flash):**\n")
        
        # –†–∞—Å—Å—É–∂–¥–µ–Ω–∏—è Flash
        if extracted_context and extracted_context.flash_reasoning:
            reasoning_preview = extracted_context.flash_reasoning[:300]
            if len(extracted_context.flash_reasoning) > 300:
                reasoning_preview += "..."
            flash_summary_parts.append(f"**–ê–Ω–∞–ª–∏–∑ Flash:**\n_{reasoning_preview}_\n")
        
        # –ë–ª–æ–∫–∏
        if added_block_ids:
            flash_summary_parts.append(f"**–¢–µ–∫—Å—Ç–æ–≤—ã–µ –±–ª–æ–∫–∏ ({len(added_block_ids)}):**")
            for bid in list(added_block_ids)[:10]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 10
                block = blocks_by_id.get(bid)
                if block:
                    page = block.page_hint if block.page_hint else "?"
                    preview = block.text[:100].replace('\n', ' ') + "..." if len(block.text) > 100 else block.text.replace('\n', ' ')
                    flash_summary_parts.append(f"‚Ä¢ `{bid}` (—Å—Ç—Ä. {page}): {preview}")
            if len(added_block_ids) > 10:
                flash_summary_parts.append(f"  _...–∏ –µ—â—ë {len(added_block_ids) - 10} –±–ª–æ–∫–æ–≤_")
        
        # –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        all_images_for_pro = collected_images + collected_zooms + (attached_images or [])
        if all_images_for_pro:
            flash_summary_parts.append(f"\n**–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è ({len(all_images_for_pro)}):**")
            for img in all_images_for_pro[:5]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 5
                desc = img.description[:80] if img.description else "–ë–µ–∑ –æ–ø–∏—Å–∞–Ω–∏—è"
                flash_summary_parts.append(f"‚Ä¢ {desc}")
            if len(all_images_for_pro) > 5:
                flash_summary_parts.append(f"  _...–∏ –µ—â—ë {len(all_images_for_pro) - 5} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π_")
        
        flash_summary = "\n".join(flash_summary_parts)
        self.sig_message.emit("system", flash_summary, None)
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ —á–∞—Ç–µ
        for img in all_images_for_pro:
            if hasattr(img, 'image_path') and img.image_path:
                self.sig_image.emit(img.image_path, f"–î–ª—è Pro: {img.description[:50] if img.description else '–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ'}")
        
        # ===== –≠–¢–ê–ü 2: PRO –ê–ù–ê–õ–ò–ó =====
        self.sig_log.emit("üß† –≠—Ç–∞–ø 2: Pro –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å–æ–±—Ä–∞–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç...")
        self.sig_message.emit("system", "üß† –≠—Ç–∞–ø 2: Pro –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å–æ–±—Ä–∞–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏ —Ñ–æ—Ä–º–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç...", None)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        self.save_message("user", self.query, images=None)
        
        flash_reasoning = ""
        if extracted_context and extracted_context.flash_reasoning:
            flash_reasoning = f"\n–ê–ù–ê–õ–ò–ó FLASH:\n{extracted_context.flash_reasoning}\n"
        
        pro_context = f"""–ö–û–ù–¢–ï–ö–°–¢ –î–õ–Ø –ê–ù–ê–õ–ò–ó–ê (—Å–æ–±—Ä–∞–Ω Flash-–º–æ–¥–µ–ª—å—é):
{flash_reasoning}

–†–ï–õ–ï–í–ê–ù–¢–ù–´–ï –¢–ï–ö–°–¢–û–í–´–ï –ë–õ–û–ö–ò ({blocks_found} —à—Ç.):
{text_blocks_str if text_blocks_str else '–¢–µ–∫—Å—Ç–æ–≤—ã–µ –±–ª–æ–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã.'}

–ó–ê–ü–†–û–° –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø:
{self.query}

–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ –∑—É–º—ã –ø—Ä–∏–∫—Ä–µ–ø–ª–µ–Ω—ã –Ω–∏–∂–µ. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –¥–∞–Ω–Ω—ã–µ –∏ –æ—Ç–≤–µ—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å."""
        
        pro_messages = [
            {"role": "system", "content": f"""{analysis_prompt}

## –§–û–†–ú–ê–¢ –û–¢–í–ï–¢–ê (JSON):

–¢–≤–æ–π –æ—Ç–≤–µ—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON —Å–æ —Å–ª–µ–¥—É—é—â–∏–º–∏ –ø–æ–ª—è–º–∏:
- `answer_markdown` (string, –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ): –ü–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å –≤ —Ñ–æ—Ä–º–∞—Ç–µ Markdown.
- `summary` (string): –ö—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ –æ—Ç–≤–µ—Ç–∞ (1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è).
- `counts` (array): –ü–æ–¥—Å—á—ë—Ç—ã –æ–±—ä–µ–∫—Ç–æ–≤ (–µ—Å–ª–∏ –ø—Ä–∏–º–µ–Ω–∏–º–æ), –∫–∞–∂–¥—ã–π —ç–ª–µ–º–µ–Ω—Ç: {{object_type, count, locations[]}}.
- `citations` (array): –°—Å—ã–ª–∫–∏ –Ω–∞ –∏—Å—Ç–æ—á–Ω–∏–∫–∏, –∫–∞–∂–¥—ã–π —ç–ª–µ–º–µ–Ω—Ç: {{image_id, coords_norm[4], note}}.
- `confidence` (string): –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ –æ—Ç–≤–µ—Ç–µ ("high", "medium", "low").
- `needs_more_evidence` (boolean): true –µ—Å–ª–∏ –Ω—É–∂–Ω—ã –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –±–æ–ª–µ–µ –ø–æ–ª–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞.
- `followup_images` (array[string]): –°–ø–∏—Å–æ–∫ ID –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ (–µ—Å–ª–∏ needs_more_evidence=true).
- `followup_zooms` (array): –°–ø–∏—Å–æ–∫ –∑–∞–ø—Ä–æ—Å–æ–≤ zoom (–µ—Å–ª–∏ needs_more_evidence=true), –∫–∞–∂–¥—ã–π —ç–ª–µ–º–µ–Ω—Ç: {{image_id, coords_norm[4], reason}}.

**–í–∞–∂–Ω–æ:** –ï—Å–ª–∏ —Ç—ã –º–æ–∂–µ—à—å –æ—Ç–≤–µ—Ç–∏—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å —Å –∏–º–µ—é—â–∏–º–∏—Å—è –¥–∞–Ω–Ω—ã–º–∏, —É—Å—Ç–∞–Ω–æ–≤–∏ `needs_more_evidence=false` –∏ –æ—Å—Ç–∞–≤—å `followup_*` –ø—É—Å—Ç—ã–º–∏.
"""}
        ]
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        all_images = collected_images + collected_zooms + (attached_images or [])
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º attached_images –≤ Google Files API –µ—Å–ª–∏ –µ—â—ë –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã
        if attached_images:
            self._upload_images_to_google_files(attached_images, llm_client)
        
        if all_images:
            pro_content = [{"type": "text", "text": pro_context}]
            for img in all_images:
                # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: Google Files URI, –ø–æ—Ç–æ–º S3 URL
                img_url = getattr(img, 'google_file_uri', None) or getattr(img, 's3_url', None)
                if img_url:
                    desc = img.description[:100] if img.description else "–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ"
                    pro_content.append({"type": "text", "text": f"[{desc}]"})
                    pro_content.append({
                        "type": "image_url",
                        "image_url": {"url": img_url}
                    })
            pro_messages.append({"role": "user", "content": pro_content})
        else:
            pro_messages.append({"role": "user", "content": pro_context})
        
        # –õ–æ–≥–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å –∫ Pro
        self._append_app_log(f"\n{'='*20} PRO –ó–ê–ü–†–û–° {'='*20}")
        self._log_full("PRO: –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç", analysis_prompt)
        self._log_full("PRO: –ö–æ–Ω—Ç–µ–∫—Å—Ç", pro_context)
        self._log_full("PRO: –ó–∞–ø—Ä–æ—Å (–ø–æ–ª–Ω—ã–π)", self._sanitize_messages_for_log(pro_messages))
        self._log_full("PRO: –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ –∑–∞–ø—Ä–æ—Å–µ", len(all_images))
        
        # –í—ã–∑—ã–≤–∞–µ–º Pro (response_json=True –¥–ª—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞)
        try:
            pro_response_json = llm_client.call_pro_model(
                pro_messages, 
                response_json=True,
                response_schema=PRO_ANSWER_SCHEMA
            )
        except Exception as e:
            err = f"–û—à–∏–±–∫–∞ Pro –º–æ–¥–µ–ª–∏: {e}"
            self.sig_log.emit(f"‚ùå {err}")
            self._log_full("PRO: –û—à–∏–±–∫–∞", str(e))
            self.sig_message.emit("assistant", f"‚ö†Ô∏è {err}", "gemini-3-pro-preview")
            self.save_message("assistant", f"‚ö†Ô∏è {err}")
            self.sig_finished.emit()
            return
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—á–µ—Ç—á–∏–∫ —Ç–æ–∫–µ–Ω–æ–≤ –ø–æ—Å–ª–µ –≤—ã–∑–æ–≤–∞ Pro
        try:
            usage = llm_client.last_usage
            if isinstance(usage, dict) and usage.get("total_tokens"):
                tt = usage.get("total_tokens")
                self._update_tokens(tt)
                self.sig_log.emit(f"Pro: –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ {tt} —Ç–æ–∫–µ–Ω–æ–≤")
        except Exception as e:
            logger.debug(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±–Ω–æ–≤–∏—Ç—å —Ç–æ–∫–µ–Ω—ã Pro: {e}")
        
        # –õ–æ–≥–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç Pro
        self._log_full("PRO: –û—Ç–≤–µ—Ç (JSON)", pro_response_json)
        
        # –ü–∞—Ä—Å–∏–º JSON –æ—Ç–≤–µ—Ç
        try:
            pro_data = json.loads(pro_response_json)
        except json.JSONDecodeError as e:
            err = f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON –æ—Ç Pro: {e}"
            self.sig_log.emit(f"‚ùå {err}")
            self._log_full("PRO: JSON error", str(e))
            self.sig_message.emit("assistant", f"‚ö†Ô∏è {err}\n\n–°—ã—Ä–æ–π –æ—Ç–≤–µ—Ç:\n{pro_response_json}", "gemini-3-pro-preview")
            self.save_message("assistant", f"‚ö†Ô∏è {err}")
            self.sig_finished.emit()
            return
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ JSON –æ—Ç–≤–µ—Ç–∞
        answer_markdown = pro_data.get("answer_markdown", "")
        needs_more_evidence = pro_data.get("needs_more_evidence", False)
        followup_images = pro_data.get("followup_images", [])
        followup_zooms = pro_data.get("followup_zooms", [])
        confidence = pro_data.get("confidence", "medium")
        
        self._log_full("PRO: answer_markdown", answer_markdown)
        self._log_full("PRO: needs_more_evidence", needs_more_evidence)
        self._log_full("PRO: confidence", confidence)
        
        # ===== –¶–ò–ö–õ –û–ë–†–ê–ë–û–¢–ö–ò TOOL CALLS –û–¢ PRO =====
        pro_step = 1
        max_pro_steps = 10
        
        while pro_step <= max_pro_steps and needs_more_evidence:
            self._append_app_log(f"\n{'='*20} PRO –®–ê–ì {pro_step} (–î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–´–ï –î–ê–ù–ù–´–ï) {'='*20}")
            
            has_new_data = False
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ followup_images
            if followup_images:
                self._log_full(f"PRO #{pro_step}: –ó–∞–ø—Ä–æ—Å—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π", followup_images)
                
                new_images = []
                for img_id in followup_images:
                    self.sig_log.emit(f"Pro –∑–∞–ø—Ä–æ—Å–∏–ª–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {img_id}")
                    entry = doc_index.images.get(img_id)
                    if not entry:
                        self._append_app_log(f"  ‚ö†Ô∏è –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ: {img_id}")
                        continue
                    
                    self._append_app_log(f"  üì• –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {img_id}")
                    try:
                        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ª–æ–∫–∞–ª—å–Ω—ã–π –ø—É—Ç—å –µ—Å–ª–∏ –Ω–µ—Ç URI
                        image_source = entry.uri if entry.uri else entry.local_path
                        if not image_source:
                            self._append_app_log(f"  ‚ö†Ô∏è –ù–µ—Ç –∏—Å—Ç–æ—á–Ω–∏–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {img_id}")
                            continue
                        
                        loaded = image_processor.download_and_process_pdf(image_source, image_id=img_id)
                        new_images.extend(loaded)
                    except Exception as e:
                        self._append_app_log(f"  ‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {img_id}: {e}")
                
                if new_images:
                    # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤ Google Files API
                    self._upload_images_to_google_files(new_images, llm_client)
                    # Fallback –Ω–∞ S3
                    self._upload_images_to_s3(new_images)
                    all_images.extend(new_images)
                    has_new_data = True
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ –∏—Å—Ç–æ—Ä–∏—é Pro
                    content_with_images = [{"type": "text", "text": "–ó–∞–≥—Ä—É–∂–µ–Ω—ã –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:"}]
                    for vc in new_images:
                        img_url = getattr(vc, 'google_file_uri', None) or vc.s3_url
                        if img_url:
                            content_with_images.append({
                                "type": "image_url",
                                "image_url": {"url": img_url}
                            })
                    pro_messages.append({"role": "user", "content": content_with_images})
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ followup_zooms
            if followup_zooms:
                self._log_full(f"PRO #{pro_step}: –ó–∞–ø—Ä–æ—Å—ã ZOOM", followup_zooms)
                
                zoom_crops = []
                for i, fz in enumerate(followup_zooms):
                    img_id = fz.get("image_id")
                    coords_norm = fz.get("coords_norm")
                    reason = fz.get("reason", "")
                    
                    # –§–ò–ö–°: –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–æ—Ä–º–∞—Ç coords_norm
                    if coords_norm and isinstance(coords_norm, list):
                        # –ï—Å–ª–∏ —ç—Ç–æ –ø–ª–æ—Å–∫–∏–π –º–∞—Å—Å–∏–≤ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç (–æ—à–∏–±–∫–∞ –º–æ–¥–µ–ª–∏), –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
                        if len(coords_norm) != 4:
                            self._append_app_log(f"  ‚ö†Ô∏è ZOOM #{i+1}: –ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç coords_norm (–æ–∂–∏–¥–∞–µ—Ç—Å—è [x1,y1,x2,y2], –ø–æ–ª—É—á–µ–Ω–æ {len(coords_norm)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤). –ü—Ä–æ–ø—É—Å–∫–∞—é.")
                            continue
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –≤—Å–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã - —á–∏—Å–ª–∞
                        if not all(isinstance(c, (int, float)) for c in coords_norm):
                            self._append_app_log(f"  ‚ö†Ô∏è ZOOM #{i+1}: coords_norm —Å–æ–¥–µ—Ä–∂–∏—Ç –Ω–µ-—á–∏—Å–ª–∞. –ü—Ä–æ–ø—É—Å–∫–∞—é.")
                            continue
                    else:
                        self._append_app_log(f"  ‚ö†Ô∏è ZOOM #{i+1}: –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç coords_norm. –ü—Ä–æ–ø—É—Å–∫–∞—é.")
                        continue
                    
                    self.sig_log.emit(f"Pro –∑–∞–ø—Ä–æ—Å–∏–ª–∞ zoom: {reason[:50]}")
                    self._append_app_log(f"  üîç PRO ZOOM #{i+1}: {img_id}, coords_norm={coords_norm}, reason={reason[:80]}")
                    
                    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
                    if isinstance(img_id, str) and img_id:
                        entry = doc_index.images.get(img_id)
                        if not entry:
                            self._append_app_log(f"  ‚ö†Ô∏è –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ: {img_id}")
                            continue
                        
                        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º
                        try:
                            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ª–æ–∫–∞–ª—å–Ω—ã–π –ø—É—Ç—å –µ—Å–ª–∏ –Ω–µ—Ç URI
                            image_source = entry.uri if entry.uri else entry.local_path
                            if not image_source:
                                self._append_app_log(f"  ‚ö†Ô∏è –ù–µ—Ç –∏—Å—Ç–æ—á–Ω–∏–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {img_id}")
                                continue
                            
                            loaded = image_processor.download_and_process_pdf(image_source, image_id=img_id)
                            # –°–æ–∑–¥–∞–µ–º zoom crop
                            zoom_output_path = self.data_root / "temp" / f"pro_zoom_{pro_step}_{i}.png"
                            zoom_result = image_processor.process_zoom_request(img_id, coords_norm, output_path=zoom_output_path)
                            if zoom_result:
                                zoom_crops.append(zoom_result)
                        except Exception as e:
                            self._append_app_log(f"  ‚ùå –û—à–∏–±–∫–∞ zoom {img_id}: {e}")
                
                if zoom_crops:
                    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∑—É–º—ã –≤ Google Files API
                    self._upload_images_to_google_files(zoom_crops, llm_client)
                    # Fallback –Ω–∞ S3
                    self._upload_images_to_s3(zoom_crops)
                    all_images.extend(zoom_crops)
                    has_new_data = True
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é Pro
                    content_with_zooms = [{"type": "text", "text": "–í—ã–ø–æ–ª–Ω–µ–Ω—ã zoom –∑–∞–ø—Ä–æ—Å—ã:"}]
                    for zc in zoom_crops:
                        desc = zc.description[:100] if zc.description else "Zoom"
                        img_url = getattr(zc, 'google_file_uri', None) or zc.s3_url
                        if img_url:
                            content_with_zooms.append({"type": "text", "text": f"[{desc}]"})
                            content_with_zooms.append({
                                "type": "image_url",
                                "image_url": {"url": img_url}
                            })
                    pro_messages.append({"role": "user", "content": content_with_zooms})
            
            # –ï—Å–ª–∏ –Ω–µ—Ç –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö - –≤—ã—Ö–æ–¥
            if not has_new_data:
                self._append_app_log("  ‚ÑπÔ∏è –ù–µ—Ç –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏")
                break
            
            # –ü–æ–≤—Ç–æ—Ä–Ω—ã–π –∑–∞–ø—Ä–æ—Å –∫ Pro
            try:
                pro_response_json = llm_client.call_pro_model(
                    pro_messages, 
                    response_json=True,
                    response_schema=PRO_ANSWER_SCHEMA
                )
            except Exception as e:
                err = f"–û—à–∏–±–∫–∞ Pro –º–æ–¥–µ–ª–∏ (—à–∞–≥ {pro_step}): {e}"
                self.sig_log.emit(f"‚ùå {err}")
                self._log_full(f"PRO —à–∞–≥ {pro_step}: –û—à–∏–±–∫–∞", str(e))
                break
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Ç–æ–∫–µ–Ω—ã
            try:
                usage = llm_client.last_usage
                if isinstance(usage, dict) and usage.get("total_tokens"):
                    self._update_tokens(usage.get("total_tokens"))
            except:
                pass
            
            # –ü–∞—Ä—Å–∏–º –æ—Ç–≤–µ—Ç
            try:
                pro_data = json.loads(pro_response_json)
                answer_markdown = pro_data.get("answer_markdown", answer_markdown)  # –û–±–Ω–æ–≤–ª—è–µ–º –æ—Ç–≤–µ—Ç
                needs_more_evidence = pro_data.get("needs_more_evidence", False)
                followup_images = pro_data.get("followup_images", [])
                followup_zooms = pro_data.get("followup_zooms", [])
                confidence = pro_data.get("confidence", confidence)
                
                self._log_full(f"PRO —à–∞–≥ {pro_step}: answer_markdown", answer_markdown)
                self._log_full(f"PRO —à–∞–≥ {pro_step}: needs_more_evidence", needs_more_evidence)
            except json.JSONDecodeError as e:
                self._log_full(f"PRO —à–∞–≥ {pro_step}: JSON error", str(e))
                break
            
            pro_step += 1
        
        if pro_step > max_pro_steps:
            self.sig_log.emit(f"‚ö†Ô∏è –î–æ—Å—Ç–∏–≥–Ω—É—Ç –ª–∏–º–∏—Ç —à–∞–≥–æ–≤ Pro: {max_pro_steps}")
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é (answer_markdown)
        # –§–ò–ö–°: –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ answer_markdown –Ω–µ –ø—É—Å—Ç–æ–π
        if not answer_markdown or not answer_markdown.strip():
            err = "‚ö†Ô∏è Pro –º–æ–¥–µ–ª—å –Ω–µ –≤–µ—Ä–Ω—É–ª–∞ —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç (answer_markdown –ø—É—Å—Ç–æ–π)"
            self.sig_log.emit(err)
            self._log_full("PRO: –û—à–∏–±–∫–∞", err)
            self.sig_message.emit("assistant", err, "gemini-3-pro-preview")
            self.save_message("assistant", err)
        else:
            self.sig_message.emit("assistant", answer_markdown, "gemini-3-pro-preview")
            self.save_message("assistant", answer_markdown, images=all_images)
        
        self._append_app_log(f"\n{'='*20} FLASH+PRO –ó–ê–í–ï–†–®–ï–ù–û {'='*20}")
        self.sig_log.emit("‚úÖ Flash + Pro –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
        self.sig_finished.emit()
