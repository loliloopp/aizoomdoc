"""
–ê–¥–∞–ø—Ç–µ—Ä –∞–≥–µ–Ω—Ç–∞ –¥–ª—è —Ä–∞–±–æ—Ç—ã –≤ GUI (PyQt6).
–° –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –≤—ã–±–æ—Ä–∞ md —Ñ–∞–π–ª–æ–≤ –∏–∑ GUI.
"""

import logging
import json
import uuid
import asyncio
from pathlib import Path
from datetime import datetime
from typing import List
from PyQt6.QtCore import QThread, pyqtSignal

from .config import config
from .llm_client import LLMClient
from .image_processor import ImageProcessor
from .markdown_parser import MarkdownParser
from .supabase_client import supabase_client
from .s3_storage import s3_storage

logger = logging.getLogger(__name__)

class AgentWorker(QThread):
    sig_log = pyqtSignal(str)
    sig_message = pyqtSignal(str, str)
    sig_image = pyqtSignal(str, str)
    sig_finished = pyqtSignal()
    sig_error = pyqtSignal(str)
    sig_history_saved = pyqtSignal(str, str)
    
    def __init__(self, data_root: Path, query: str, model: str, md_files: List[str] = None):
        super().__init__()
        self.data_root = data_root
        self.query = query
        self.model = model
        self.md_files = md_files or []
        self.is_running = True
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.chat_id = f"{timestamp}_{uuid.uuid4().hex[:6]}"
        
        self.chat_dir = data_root / "chats" / self.chat_id
        self.images_dir = self.chat_dir / "images"
        self.chat_dir.mkdir(parents=True, exist_ok=True)
        self.images_dir.mkdir(parents=True, exist_ok=True)
        
        self.chat_history_data = {
            "id": self.chat_id,
            "timestamp": timestamp,
            "query": query,
            "model": model,
            "md_files": self.md_files,
            "messages": []
        }
        self.db_chat_id = None

    def save_message(self, role: str, content: str, images: list = None):
        msg = {
            "role": role,
            "content": content,
            "timestamp": datetime.now().isoformat()
        }
        if images:
            msg["images"] = [img.image_path for img in images if img.image_path]
        
        self.chat_history_data["messages"].append(msg)
        self._save_to_disk()
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –ë–î –∏ S3
        if config.USE_DATABASE:
            try:
                asyncio.run(self._save_to_db(role, content, images))
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ –ë–î: {e}")

    async def _save_to_db(self, role: str, content: str, images: list = None):
        """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è –∏ –∫–∞—Ä—Ç–∏–Ω–æ–∫ –≤ Supabase –∏ S3."""
        try:
            # 1. –°–æ–∑–¥–∞–µ–º —á–∞—Ç –µ—Å–ª–∏ –µ—â–µ –Ω–µ —Å–æ–∑–¥–∞–Ω
            if not self.db_chat_id:
                title = self.query[:100]
                self.db_chat_id = await supabase_client.create_chat(
                    title=title,
                    user_id="default_user",
                    description=self.query,
                    metadata={
                        "local_chat_id": self.chat_id,
                        "model": self.model,
                        "md_files": self.md_files
                    }
                )
                if not self.db_chat_id:
                    logger.warning("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å —á–∞—Ç –≤ Supabase")
                    return

            # 2. –î–æ–±–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ
            msg_id = await supabase_client.add_message(
                chat_id=self.db_chat_id,
                role=role,
                content=content
            )
            
            if not msg_id:
                logger.warning("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ Supabase")
                return

            # 3. –ï—Å–ª–∏ –µ—Å—Ç—å –∫–∞—Ä—Ç–∏–Ω–∫–∏ - –∑–∞–≥—Ä—É–∂–∞–µ–º –≤ S3 –∏ —Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º
            if images:
                for img in images:
                    if not img.image_path or not Path(img.image_path).exists():
                        continue
                        
                    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –ø—É—Ç—å –≤ S3
                    img_type = "zoom_crop" if img.is_zoom_request else "viewport"
                    filename = Path(img.image_path).name
                    s3_key = s3_storage.generate_s3_path(self.db_chat_id, img_type, filename)
                    
                    # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤ S3
                    s3_url = await s3_storage.upload_file(img.image_path, s3_key)
                    
                    if s3_url:
                        # –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º –≤ –ë–î
                        await supabase_client.add_image_to_message(
                            chat_id=self.db_chat_id,
                            message_id=msg_id,
                            image_name=filename,
                            s3_path=s3_key,
                            s3_url=s3_url,
                            image_type=img_type,
                            description=img.description
                        )
                    else:
                        logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å {filename} –≤ S3")
                        
        except Exception as e:
            logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ _save_to_db: {e}", exc_info=True)

    def _save_to_disk(self):
        history_path = self.chat_dir / "history.json"
        with open(history_path, "w", encoding="utf-8") as f:
            json.dump(self.chat_history_data, f, indent=2, ensure_ascii=False)
        self.sig_history_saved.emit(self.chat_id, self.query)

    def run(self):
        try:
            self.sig_log.emit(f"–°—Ç–∞—Ä—Ç —á–∞—Ç–∞ {self.chat_id}...")
            
            image_processor = ImageProcessor(self.data_root)
            image_processor.temp_dir = self.images_dir
            
            llm_client = LLMClient(model=self.model, data_root=self.data_root)
            
            # –ï—Å–ª–∏ —É–∫–∞–∑–∞–Ω—ã –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ md —Ñ–∞–π–ª—ã —á–µ—Ä–µ–∑ GUI - –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏—Ö
            # –ò–Ω–∞—á–µ –±–µ—Ä–µ–º result.md –∏–∑ data_root
            full_text = ""
            all_blocks = []  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Å–µ –±–ª–æ–∫–∏ –¥–ª—è –ø–æ—Å–ª–µ–¥—É—é—â–µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
            
            if self.md_files:
                self.sig_log.emit(f"–ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –≤—ã–±—Ä–∞–Ω–Ω—ã–µ MD —Ñ–∞–π–ª—ã: {len(self.md_files)}")
                for md_path_str in self.md_files:
                    try:
                        md_path = Path(md_path_str)
                        self.sig_log.emit(f"–ß–∏—Ç–∞—é: {md_path}")
                        
                        # –ü–µ—Ä–µ–¥–∞–µ–º Path –æ–±—ä–µ–∫—Ç, –∞ –Ω–µ —Å—Ç—Ä–æ–∫—É
                        parser = MarkdownParser(md_path)
                        blocks = parser.parse()
                        all_blocks.extend(blocks)  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –±–ª–æ–∫–∏
                        
                        self.sig_log.emit(f"–ü—Ä–æ—á–∏—Ç–∞–Ω–æ –±–ª–æ–∫–æ–≤: {len(blocks)}")
                        for block in blocks:
                            full_text += block.text + "\n\n"
                    except Exception as e:
                        self.sig_log.emit(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è {md_path_str}: {e}")
                        import traceback
                        self.sig_log.emit(traceback.format_exc())
            else:
                # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –±–µ—Ä–µ–º result.md
                self.sig_log.emit(f"–ò—â—É result.md –≤ {self.data_root}")
                markdown_path, _ = config.get_document_paths(self.data_root)
                if Path(markdown_path).exists():
                    parser = MarkdownParser(markdown_path)
                    blocks = parser.parse()
                    all_blocks = blocks  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –±–ª–æ–∫–∏
                    for block in blocks:
                        full_text += block.text + "\n\n"
                else:
                    err_msg = f"result.md –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ {self.data_root}. –í—ã–±–µ—Ä–∏—Ç–µ MD —Ñ–∞–π–ª—ã —á–µ—Ä–µ–∑ '–û–±–∑–æ—Ä MD...' –∏–ª–∏ —É–∫–∞–∂–∏—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω—É—é –ø–∞–ø–∫—É –≤ –ù–∞—Å—Ç—Ä–æ–π–∫–∞—Ö."
                    self.sig_error.emit(err_msg)
                    raise FileNotFoundError(err_msg)
            
            if not full_text.strip():
                raise ValueError("–î–æ–∫—É–º–µ–Ω—Ç –ø—É—Å—Ç")
            
            self.sig_log.emit("–ê–Ω–∞–ª–∏–∑ –∑–∞–ø—Ä–æ—Å–∞ –∏ –≤—ã–±–æ—Ä –∫–∞—Ä—Ç–∏–Ω–æ–∫...")
            print(f"[GUI_AGENT] –í—ã–∑—ã–≤–∞—é select_relevant_images –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞: {self.query}")
            print(f"[GUI_AGENT] –†–∞–∑–º–µ—Ä –¥–æ–∫—É–º–µ–Ω—Ç–∞: {len(full_text)} —Å–∏–º–≤–æ–ª–æ–≤")
            selection = llm_client.select_relevant_images(full_text, self.query)
            print(f"[GUI_AGENT] –†–µ–∑—É–ª—å—Ç–∞—Ç: needs_images={selection.needs_images}, –∫–∞—Ä—Ç–∏–Ω–æ–∫={len(selection.image_urls)}")
            print(f"[GUI_AGENT] Reasoning: {selection.reasoning}")
            
            self.sig_log.emit(f"–í—ã–±—Ä–∞–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {len(selection.image_urls)}")
            
            downloaded_images = []
            if selection.needs_images and selection.image_urls:
                info_msg = f"üîé *–ê–Ω–∞–ª–∏–∑:* {selection.reasoning}\n–°–∫–∞—á–∏–≤–∞—é {len(selection.image_urls)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π..."
                self.sig_message.emit("assistant", info_msg)
                self.save_message("assistant", info_msg)
                
                for url in selection.image_urls:
                    if not self.is_running: return
                    self.sig_log.emit(f"–°–∫–∞—á–∏–≤–∞–Ω–∏–µ: {url}")
                    
                    crop_info = image_processor.download_and_process_pdf(url)
                    if crop_info:
                        downloaded_images.append(crop_info)
                        if crop_info.image_path:
                            self.sig_image.emit(crop_info.image_path, f"–ò—Å—Ç–æ—á–Ω–∏–∫: {url}")
            else:
                msg = "–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–µ —Ç—Ä–µ–±—É—é—Ç—Å—è."
                self.sig_message.emit("assistant", msg)
                self.save_message("assistant", msg)

            llm_client.init_analysis_chat()
            
            # –ü–µ—Ä–µ–¥–∞–µ–º –í–ï–°–¨ –¥–æ–∫—É–º–µ–Ω—Ç - –æ—Ç–≤–µ—Ç –º–æ–∂–µ—Ç –±—ã—Ç—å –≤ –ª—é–±–æ–º –±–ª–æ–∫–µ
            context = f"–î–û–ö–£–ú–ï–ù–¢:\n{full_text}\n\n–ó–ê–ü–†–û–° –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø: {self.query}"
            
            print(f"[GUI_AGENT] –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –∞–Ω–∞–ª–∏–∑-—á–∞—Ç")
            print(f"[GUI_AGENT] –†–∞–∑–º–µ—Ä –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞: {len(context)} —Å–∏–º–≤–æ–ª–æ–≤")
            print(f"[GUI_AGENT] –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞—Ä—Ç–∏–Ω–æ–∫: {len(downloaded_images)}")
            
            self.save_message("user", self.query, images=downloaded_images)
            
            llm_client.add_user_message(context, images=downloaded_images)
            
            step = 0
            max_steps = 5
            
            while step < max_steps and self.is_running:
                step += 1
                print(f"[GUI_AGENT] === –®–ê–ì {step} ===")
                self.sig_log.emit(f"–®–∞–≥ {step}...")
                
                response = llm_client.get_response()
                print(f"[GUI_AGENT] –ü–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç –¥–ª–∏–Ω–æ–π {len(response)} —Å–∏–º–≤–æ–ª–æ–≤")
                print(f"[GUI_AGENT] –ü–µ—Ä–≤—ã–µ 300 —Å–∏–º–≤–æ–ª–æ–≤ –æ—Ç–≤–µ—Ç–∞: {response[:300]}")
                
                zoom_reqs = llm_client.parse_zoom_request(response)
                print(f"[GUI_AGENT] Zoom –∑–∞–ø—Ä–æ—Å–æ–≤: {len(zoom_reqs)}")
                
                if zoom_reqs:
                    zoom_crops = []
                    for i, zr in enumerate(zoom_reqs):
                        zoom_msg = f"üîÑ *Zoom [{i+1}/{len(zoom_reqs)}]:* {zr.reason}"
                        self.sig_log.emit(zoom_msg)
                        self.sig_message.emit("assistant", zoom_msg)
                        self.save_message("assistant", zoom_msg)
                        
                        zoom_crop = image_processor.process_zoom_request(
                            zr,
                            output_path=self.images_dir / f"zoom_step_{step}_{i}.png"
                        )
                        
                        if zoom_crop:
                            zoom_crops.append(zoom_crop)
                            if zoom_crop.image_path:
                                self.sig_image.emit(zoom_crop.image_path, f"Zoom {i+1}")
                        else:
                            self.sig_log.emit(f"–û—à–∏–±–∫–∞ Zoom {i+1}")

                    if zoom_crops:
                        llm_client.add_user_message("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã Zoom:", images=zoom_crops)
                    else:
                        llm_client.add_user_message("–û—à–∏–±–∫–∞ Zoom: –Ω–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã.")
                else:
                    self.sig_message.emit("assistant", response)
                    self.save_message("assistant", response)
                    self.sig_finished.emit()
                    return

            if self.is_running:
                err = "–õ–∏–º–∏—Ç —à–∞–≥–æ–≤."
                self.sig_error.emit(err)
                self.save_message("system", err)
                
        except Exception as e:
            logger.error(f"Error: {e}", exc_info=True)
            self.sig_error.emit(str(e))
            self.sig_finished.emit()

    def stop(self):
        self.is_running = False
